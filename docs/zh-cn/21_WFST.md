## WFST：Weight Finite State Transducer

<!-- https://blog.csdn.net/weixin_55267022/article/details/118082886 -->
<!-- https://zhuanlan.zhihu.com/p/369054845 -->

<!-- http://fancyerii.github.io/wfst/wfst/ -->
<!-- http://fancyerii.github.io/books/wfst/ -->

!> 这部分内容略显复杂！

### 1.WFST简介

基于HMM的语音识别系统中最复杂的是解码器，它需要融合来自声学模型、发音词典和语言模型的信息，在巨大的搜索空间里寻找最优的路径。WFST提供了统一的框架，能够用统一的方式表示这些模型并且融合起来，从而可以达到很快的搜索速度。本文介绍WFST的基本概念以及它在语音识别中的应用。在介绍加权有限状态转换器(Weighted Finite State Transducer, WFST)的概念之前，我们首先介绍有穷自动机(有限状态自动机)。

#### 1.1 有穷自动机(FA)

自动机(automaton,复数是Automata)来源于希腊单词”αὐτόματα”，它表示一个根据预先设置的指令序列自动执行的机器。一个包含有限个状态的自动机就叫作有穷自动机(Finite Automaton)或者有限状态机(Finite State Machine)。

##### 1.1.1 确定有穷自动机(Deterministic Finite Automaton, DFA)

一个确定有穷自动机由一个五元组$(Q,Σ,δ,q_0,F)$表示，其中：

+ $Q$是一个有限的状态集合
+ $Σ$是字母表
+ $δ$是状态转移函数：$δ:Q×Σ→Q$
+ $q_0$是初始状态，$q_0∈Q$
+ $F$是终止状态的集合，$F⊆Q$

字母表(Alphabeta)是任意有限符号的集合，比如$\Sigma=\{ a,b,c,d \} $就是一个字母表，它包含符号”a”,”b”,”c”,”d”。字符串(String)是由字母表中的字符组成的串。比如”cabcad”就是$Σ={a,b,c,d}$上的一个合法字符串，而”abf”则不是，因为”f”不是字母表中的符号。字符串中符号的个数叫作字符串的长度，比如字符串”cabcad”的长度是6。长度为0的字符串叫作空字符串，一般记作$λ$或者$ϵ$。两个字符串的拼接(concatenation)就是把两个字符串的字符按照顺序拼接起来。

$Σ_i$表示字母表$Σ$上所有长度为$i$的字符串的集合。比如$Σ={a,b}$，那么$Σ_1={a,b}$，$Σ_2={aa,ab,ba,bb}$，而$Σ_0={λ}$。Kleene Star是定义在字母表上的一个一元操作，它是字母表上所有字符串的集合。$Σ_∗=Σ_0∪Σ_1...$。如果$Σ={a,b}$，那么$Σ_∗={λ,a,b,aa,ab,ba,bb,...}$。而Kleene Plus操作和Keene Star类似，只是它不包含空字符串。

一个语言(Language)是$Σ_∗$的一个子集，比如$Σ={a,b}$上所有长度为2的字符串就构成了一个语言$L={aa,ab,ba,bb}$。

我们可以用一个图来表示一个状态机，其中：
+ 点代表状态
+ 边代表状态之间的跳转，边上的字符代表跳转的输入
+ 我们在初始状态所在的点上画一条入边来表示它是初始状态
+ 终止状态用两个圈表示
比如我们有一个状态机：

+ $Q=\{a,b,c\}$
+ $\Sigma=\{0,1\}$
+ $q_0=a$
+ $F=\{c\}$

它对应的状态转移表如下表：

<div align=center>
    <img src="zh-cn/img/ch17/p1.png"   /> 
</div>

下图是一个DFA的图形表示:

<div align=center>
    <img src="zh-cn/img/ch17/p2.jpg"   /> 
</div>

一个DFA识别的语言定义为这样的字符串——从初始状态根据字符串的字符来跳转，最终把字符串“消费”完成后停止在终止状态。给定一个DFA和一个字符串，我们可以这样来判断：首先状态机的状态是初始状态，然后根据字符串的第一个字符跳转到第二个状态，然后根据第二个字符串跳转到第三状态，…，根据最后所有的字符都处理完成后的状态机所在的状态来判断状态机是否“接受”这个字符串——如果是终止状态就接受，否则拒绝。

根据上面的方法，理论上我们可以这样得到状态机识别的语言：变量所有可能的字符串，然后用上面的方法判断这个字符串是否被DFA接受，接受的话加到识别的集合里。当然实际我们无法这样操作（或者通常也不需要列举出某个DFA识别的所有字符串，因为通常DFA识别的字符串是无穷的）。

比如字符串”1101011”是上面DFA识别语言中的一个字符串，而”100”不是。读者可以思考一下这个自动机表示的语言到底包含(不包含)哪些字符串。


因此DFA的一个用途可以是“识别”一种语言——也就是判断一个字符串是否属于这个语言。可以证明，任何正则表达式描述的语言都可以找到一个等价的DFA，反之亦然。比如下图DFA可以识别以”ing”结尾的字符串。请读者验证一下它确实可以(且仅可以)识别”ing”结尾的字符串。然后我们再来思考一下如果我们自己来设计一个DFA来识别”ing”应该怎么做？

我们来分析一下为什么这个DFA可以识别”ing”结尾的字符串。首先它初始化状态是”nothing”表示没有识别到”ing”的任何部分。而这个状态如果遇到”i”，那么就会进入”Saw i”(见到i)的状态；如果它遇到非i的字符，仍然处于”nothing”状态。在”Saw i”的状态遇到n会进入”Saw n”的状态；遇到i那么还是状态不变；而遇到i和n之外的其它字符都是跳到”nothing”的状态。而在”Saw n”的状态遇到g就进入”Saw ing”的状态，这个状态是一个终止状态；如果遇到i它会跳到”Saw i”的状态；遇到其它字符就好跳到”nothing”状态。注意在”Saw n”状态遇到n还是跳到”nothing”，比如字符串doinn，在第二个n的时候说明前面的in不可能是ing了，所以必须回到”nothing”状态从新搜索”ing”。在”Saw ing”的终止状态如果遇到了i，那么还是进入”Saw i”的状态，否则就回到”nothing”状态。

<div align=center>
    <img src="zh-cn/img/ch17/p3.png"   /> 
</div><p align=center>识别ing结尾的字符串的DFA</p>

我们再来看一个DFA，如下图所示，它识别包含baba的字符串。

<div align=center>
    <img src="zh-cn/img/ch17/p4.png"   /> 
</div><p align=center>识别包含baba的字符串的DFA</p>

DFA的每一个状态在遇到一个字符的时候有且只有一条边跳到另一个状态(或者跳到自己)，这样的FA是确定的。如果字母表的大小是N，那么每个点出发的边一定也是N。为了简化，我们通常假设有一个“死”的状态，它不是终止状态，并且进入这个状态后遇到任何输入都是跳转到自己上。如下图所示，我们的DFA只识别”then”这个字符串，因此第一个状态只有遇到t会跳到下一个状态，其它非t的输入都会跳转到“死”状态。为了简化，我们通常可以把死状态以及跳到死状态的边去掉。这样如果DFA在某个状态遇到某个输入无法跳转(没有边可以走)就认为它进入“死”状态了。


<div align=center>
    <img src="zh-cn/img/ch17/p5.png"   /> 
</div><p align=center>包含吸收死状态的DFA</p>


##### 1.1.2 非确定有穷自动机(Non-deterministic Finite Automaton/NFA)

DFA每个状态遇到任何一个输入有且仅有一个跳转(边)，我们可以对DFA进行扩展，使得一个状态遇到一个输入可以(当然不一定)有多余一条边。那这就带来一个问题：状态机执行的时候有多条边到底跳到哪个状态呢？答案是多条边都“同时”跳转，有点像状态机的“分裂”，原来只有一个状态机，现在遇到某个输入有多个跳转，一个状态机就“分裂”成多个状态机，然后到下一个输入的时候同时执行多个状态机，当然往后也可能继续“分裂”。当然某些分裂的状态机会遇到不能跳转的情况(进入死状态)，我们就认为它“死”掉了。最后字符串的字符都消费完了之后，如果至少一个分裂的状态机停止在终止状态，那么我们就认为这个状态机接受这个字符串，否则不接受。

这样看起来，NFA是“包含”DFA的，或者说DFA是一种特殊的NFA，它的每个状态在遇到一个输入字符是有且只有一条边。因此DFA描述的语言是包含在NFA里的。或者更加正式的说法是：任意给定一个DFA，我们可以构造一个NFA，这个NFA识别的语言是和DFA相同的(语言是一个集合，语言相同就是集合相同的意思，通常我们证明两个集合A和B相同的方法是证明$A⊆B$并且$B⊆A$)。这是很显然的，我们构造一个和这个DFA一模一样的另外一个DFA，然后把它“叫作”NFA就行了。

但是是否存在一个NFA，我们没有办法构造出一个与之等价的DFA呢？从直觉上似乎应该存在，因为看起来NFA的描述能力更强。不过这个直觉是错误的，虽然NFA看起来更强大，但是对于任意一个NFA，我们都可以构造出一个与之等价的DFA来，下面的章节会介绍怎么构造，我们这里先承认这个结论就行了。这就有个问题：既然NFA不比DFA强大，那么我们研究它还有什么用处吗？答案是：为了识别某种语言，NFA更容易构造出来。我们用一个例子来说明这一点。

比如假设字母表是$Σ=\{0,1\}$，我们需要识别一种语言$L=\{w|w的最后一个字符是1\}$。这看起来是个很简单的语言，我们尝试用DFA来识别它。读者可以拿出纸笔来试一试。

如图是一个可以识别这个语言的一个DFA，请读者验证其正确性。我们可以发现，如果给了我们一个DFA，然后我们来验证，就会很容易的发现：“哦，确实这个DFA可以识别这个语言/字符串”。但是让我们来想(构造)出一个识别这个语言的DFA就会觉得很难。但是NFA却不是这样，有了一些经验之后，我们会发现设计一个NFA很容易，甚至我们可以把构造的过程变成固定的“流程”，这意味着可以用程序来构造NFA。当然并不是所有的语言都可以用NFA/DFA来识别，后面我们会介绍正则表达式，任何一个正则表达式都可以很容易的构造出一个等价的NFA来。注意我们在很多语言或者工具里提供的正则表达式很多都不是“真正”的正则表达式，它们加了很多“扩展”从而导致它们的表达能力更强，但是它们表达的语言无法用DFA/NFA来识别，比如back reference

下面我们来“设计”一个NFA识别倒数第3个字符是1的字符串的语言。如下图所示，我们首先有个$q_0$状态，它遇到1就跳到$q_1$状态，这表示它是倒数第3个位置，然后不管输入是0还是1都跳到$q_2$——倒数第二个位置。然后不管输入是什么，$q_2$都跳到$q_3$——被接受的最后一个字符。为什么它就能够识别倒数第3个是1的字符串呢？

<div align=center>
    <img src="zh-cn/img/ch17/p6.png"   /> 
</div><p align=center>识别倒数第3个是1的字符串的NFA</p>

我们来分析一下，开始我们在状态$q_0$，如果遇到0，那么它还是在这个状态。如果遇到1，它既可以留着状态$q_0$，也可以跳到状态$q_1$。状态$q_1$是我们“猜测”的可能的倒数第三个位置（但是我们现在不可能知道后面还有几个字符，我们只是猜测有这种可能），如果我们没猜对呢？也没关系，还有一个“分裂”的状态机在状态$q_0$。如果运气好猜对了，那么后面不过输入什么我们都跳到$q_2$，再不过输入是什么我们都跳到$q_3$，然后结束（因为我们猜对了，所以$q_1$后面有且仅有两个字符)。

我们用一个例子来验证一下。比如”010101”是L中的一个字符串，因为倒数第3个字符是1。NFA的分裂过程如下表所示：

<div align=center>
    <img src="zh-cn/img/ch17/p7.png"   /> 
</div>

我们可以发现，在时刻2（遇到第一个1），NFA猜测了一次它是倒数第三个字符(分裂了一次)，但是到第5个时刻发现不是（因为这个时候它至少是倒数第4个字符了）。在时刻4又猜测了一次，这次运气很好猜对了。在时刻6又猜测了一次，结果没有猜对，因为它是最后一个1，后面没有别的字符了。

##### 1.1.3 通过子集构造把NFA转换成DFA

我们这里介绍把NFA转换成DFA的子集构造法，我们只介绍怎么使用这个算法，不会证明这种方法构造出来的DFA和NFA是等价的，有兴趣的读者可以找一些形式语言与自动机的资料（可能有些编译原理课程也会介绍）

子集构造的核心概念是ϵ-闭包(ϵ−closure)算法。比如下图所示的NFA，它可以识别的语言是`”a*b*c*“`(请读者验证)。ϵ-闭包算法的输入是一个NFA的状态集合，比如`{1}`，它的输出也是一个状态集合，其中输出集合的每一个状态都是可以从输入状态经过全是ϵ的边跳转到这个状态。因此如果输入是`{1}`，那么它的ϵ-闭包是集合`{1,2}`，因为1可以通过空跳转到自己，而1也可以通ϵ跳转到2。类似的输入`{0}`的ϵ-闭包是集合`{0,1,2}`，因为0可以通过ϵ跳转到1，而1又可能通过ϵ跳转到2。


<div align=center>
    <img src="zh-cn/img/ch17/p8.png"   /> 
</div>

子集构造的过程如下图所示。NFA的初始状态是0，我们首先得到它的ϵ-闭包{0,1,2}，我们把它作为DFA的一个状态，因为它包含NFA的初始状态0，因此它也是DFA的初始状态；同时它包含NFA的终止状态2，因此它也是DFA的终止状态。

接着我们看DFA的状态`{0,1,2}`输入字母`a`的情况，状态0输入`a`还是0，而状态`1`和`2`不能输入`a`，因此`{0,1,2}`输入`a`可以得到`0`，而0的ϵ-闭包是`{0,1,2}`，因此`{0,1,2} -a->{0,1,2}`。再看`{0,1,2}`输入b的情况，0和2不能输入b，只有状态1遇到b后还是状态1，因此`{0,1,2}`遇到b的”直接”输出是{1}，而{1}的ϵ-闭包是`{1,2}`，因此最终`{0,1,2}-b->{1,2}`。类似的，我们可以得到`{0,1,2}-c->{2}`。

这个时候的状态除了`{0,1,2}`又多了`{1,2}`和`{2}`，我们再来看第二行状态`{1,2}`的跳转。首先是`{1,2}`输入a，跳不到任何状态，因此输出是空集`∅`，空集的ϵ-闭包还是空集。然后是`{1,2}`输入b，2遇到b没有，1遇到b还是1，然后1的ϵ-闭包是{1,2}，因此`{1,2}-b->{1,2}`。后面的过程都是类似的，当处理完空集后没有产生任何新的状态，因此整个过程结束。

<div align=center>
    <img src="zh-cn/img/ch17/p10.png"   /> 
</div> <p align=center>通过子集构造把NFA转换成DFA</p>

##### 1.1.4 DFA的Minimization

给定一个DFA A，存在一个”最小的”DFA min(A)，这个DFA的状态数是所有与A等价的DFA中最小的。DFA最小化之后可以进一步压缩空间和提高识别速度，我们这里就不介绍具体的算法了。有兴趣的读者可以参考wiki或者其它资料


#### 1.2 加权有限状态转换器(WFST)

传统的语音识别模型的组件比如HMM、发音词典、语言模型等都可以用WFST来表示。`FST与FSA相比每条边多了一个输出字符串`，这样FST可以看成一个关系，把输入字符串映射成另外一个字符串(可能完全不同的字母表)输出出来。而`WFST在FST的基础上每条边以及结束状态上有一个权重`，从而每一个可接受输入字符串都对应一条路径，路径上的权重以及终止状态(可接受的字符串最终要走到终止状态)的权重通过某个运算整合起来（最常见的比如加起来）就是输入字符串对应的权重。在语音识别里权重通常用来表示概率，但WFST的理论其实不要求它有什么具体意义。

注意：WFST定义了一种关系而不是一个函数。给定一个输入(字符串)，函数只有一个唯一确定的输出(字符串)；而关系不同，给定一个输入(字符串)，可以有多个输出(字符串)

##### 1.2.1 加权的接受器(Weighted Acceptors)

WFSA在FSA的基础上输出一个权重，下图是在语音识别中使用WFSA的几个例子。下图(a)是语言模型的例子，下图(b)是发音词典，而下图(c)是一个音子的HMM，每个音子都三状态从左到右的HMM，因此它可以接受”d1+ d2+ d3+”，+表示出现一次或者多次。

<div align=center>
    <img src="zh-cn/img/ch17/p11.png"   /> 
</div> <p align=center>WFSA在语音识别中的例子</p>

我们这里不用形式化的定义，而用自然语言来描述：一个WFSA有很多状态，有一个初始状态（图中一般画成粗的圆圈），一个或者多个终止状态。边表示状态的跳转，除了对应的起点和终点，边上还有一个原标签(source label，也叫输入标签)和一个权值(weight)。我们可以把WFSA看作一个Python的`dict:string->double`，输入一个字符串，首先可以告诉你这个字符串是否在在dict里（WFSA是否接受这个字符串），如果在dict里，还可以知道它对应的权值。


##### 1.2.2 加权的转换器(Weighted Transducers)

在语音识别中我们通常使用WFST，因为我们通常需要把语言模型和发音词典“融合”起来使用。WFST和WFSA类似，只是边上除了输入标签之外还多了一个输出标签。在下图中，(a)是语言模型的WFST，和WFSA基本一样，输入和输出字符串一模一样，因为语言模型是最终的输出，所以我们这样来构造。而(b)是发音词典的WFST，输入是因子，输入是单词。注意这个WFST不是确定的，因此我们看到输入”d”的时候，两条边都要尝试，如果接下来我们输入的是”uw”，则输出”dew”+”eps”=”dew”。后面我们会讲到WFST的确定化(Determinization)，确定的WFST在每个状态的每个输入字母最多只有一条边，这样识别就会非常简单（和NFA->DFA的确定化类似）。我们可以把图(c)也扩展成WFST，其中输入是音子的id，输出就是pdf-id。因此WFST可以看成输入和输出的二元关系（注意它不是函数，因为一个输入可能有多条路径从而对应多个输出，如果对抽象代数不了解的读者可以忽略这些形式化的术语，简单来说就是给定一个输入字符串，WFST可以输出0个或者多个）。

<div align=center>
    <img src="zh-cn/img/ch17/p12.png"   /> 
</div> <p align=center>WFST在语音识别中的例子</p>

下面介绍WFST的常见运算(Operation)。


##### 1.2.3 复合(Composition)操作

复合操作用来把两个不同层级的WFST“整合”成一个WFST。比如发音词典会告诉我们一个单词对应的音子，因此我们可以构造一个WFST L来把音子的序列转换成单词的序列以及对应的概率，如上图(b)所示。此外我们有一个文法（或者统计语言模型）告诉我们单词序列概率，我们也可以构造一个G来表示这个文法或者统计语言模型，如上图(a)所示，不过G的特点是输入和输出是一样的，我们其实只关系其权值(概率)，这样我们通过复合操作`L∘G`来得到一个新的WFST，它的输入是一个音子的序列，输出是(所有)单词序列及其对于概率。

我们下面来非形式化的定义复合操作`T1∘T2`：如果在T1中有一条路径把输入字符串`u`映射到输出字符串`w`，并且在T2中有一条路径把输入字符串从`w`映射成`v`，那么在`T1∘T2`中就存在一条路径把输入字符串`u`映射到`v`，而且其权值是T1映射的权值与T2映射的权值计算出来的，如果我们认为权值是概率，那么这个操作通常就是乘法，如果是log之后的概率，那么操作就是加法。当然这是对于语音识别任务来说的，从数学上来讲，任何二元操作(函数)都是可以的，只要它和路径权值的计算那个操作可以构成一个半环(semiring)即可。这里稍微有一些抽象代数的群环域知识，计算机专业课程离散数学也会有介绍，不了解的读者可以忽略，不影响继续阅读。


我们来看一个复合操作的例子，参考下图请读者自己动手做一做简单的练习，这个图是把a和b的WFST复合成c的WFST为了简单，我们把图a、图b和图c的WFST叫做A,B,C。首先我们构造C的状态，理论上A的每一个状态和B的每一个状态都可以组成一个C中的状态，比如A有4个状态，B有3个状态，那么C就有`4×3=12`个状态，但是因为很多状态都不能从初始化状态走的，其实也就没有意义存在，所以实际我们可以从初始化状态开始，需要的时候才增加c的状态(lazy)。


<div align=center>
    <img src="zh-cn/img/ch17/p13.png"   /> 
</div> <p align=center>WFST复合操作的例子</p>


因此我们第一步把A的初始状态0和B的初始状态0“复合”成C的初始状态(0,0)。在A中`0 -a:b/0.1-> 1`，而在B中有`0 -b:c/0.3 -> 1`，因此在C中有 `(0,0) -a:c/0.4->(1,1)`。同理，在A中有`1 -c:a/0.3 -> 1`，在B中有`1 -a:b/0.4 -> 2`，因此在C中有`(1,1) -c:b/0.7 -> (1,2)`。其它的边请读者一一验证。因为3是A的终止状态(之一)，2是B的终止状态(之一)，因此(3,2)是C的终止状态(之一)。`(3,2)`的权值是`1.3`是1的权值`0.6`加上2的权值`0.7`。

最后，我们来验证一些复合操作的效果。我们可以发现WFST A中会有映射 `aca:baa/1.4(1.4=0.1+0.3+0.4+0.6)`，B中有`baa:cbb/2`，而在C中确实有`aca:cbb/3.4`。


##### 1.2.4 确定化(Determinization)操作

前面说了，如果WFST有ϵ空转移的边，或者从一个状态遇到一个字母会有两条及其以上的边，那么它就是非确定的。非确定的WFST/WFSA/FSA相比于确定的WFST/WFSA/FSA会更加难于判定某个字符串是否是它可以接受的。确定化的算法就是把一个非确定的WFST转换成等价的确定的WFST的算法。两个WFST等价的定义是：如果第一个WFST接受输入x并且可以把它映射成y且权重是w，那么第二个WFST也一定接受输入x并且能把它映射成y，权重也是w；反之亦然。

我们可以采样类似FSA/FST的子集构造(subset construction)方法来实现从非确定性WFST到等价确定WFST的转换，但是和FSA/FST不同，并不是所有的非确定的WFST都可以转换成一个等价的确定的WFST，不过还好，对于语音识别来说，大部分WFST都是可以的，某些即使不可以，我们有可以通过一些简单的变化使得它可以。后面会介绍这些技巧。

为了消除冗余的路径，我们需要一个操作(operation)合并相同标签(label)的路径的权值。如果每条路径都代表不同的一个事件，而路径的权值表示事件的概率，那么操作就是加法。而如果我们只保留最可能的路径，那么操作就是max函数，这就叫viterbi近似(viterbi approximation)。如果权值表示概率的负log（-log(prob)）,那么加法就要变成log加法，而max就要变成min函数。一般情况，我们用符号⨂表示计算路径权值的操作(怎么把边的权值整合成路径的权值)，而用符号⨁来合并相同路径的权值。常见的⨁和⨂组合包括(max,+),(+,∗),(min,+),(−log(e−x+e−y),+)。在语音识别中，前两个的权值表示概率，后两个表示概率的负log值。后面我们会看到操作并不限于这些，只有它们能构成半环即可。(min,+),(−log(e−x+e−y),+)分别叫做热带半环(tropical semiring)和log半环。热带半环这个名字听起来有些奇怪，真实原因是发现这个半环的数学家来自巴西，巴西是个热带国家，因此就叫做热带半环了。。。

普通的NFA可以通过前面我们介绍过的子集构造来变成确定性的DFA，给定输入字符串，所有可以从初始状态消费掉这个字符串后到达的状态都放到一个集合里组成一个新的状态。但是在WFST/WFSA里，相同的输入字符串可能有多条不同权重的路径，我们也会把最终到达的状态合并成一个，边则采用最短的那条。但是我们还是需要把那些较长的变多余的weight记录下来。

如下图所示，左图是一个非确定的WFSA，而右图是与之等级的确定的WFSA。

<div align=center>
    <img src="zh-cn/img/ch17/p14.png"   /> 
</div> <p align=center>WFSA Determinization示例</p>

从状态0出发输入a后可以进入1和2两个状态，路径的weight分别是1和2，我们可以把状态1和2合并成一个状态`<1,2>`，但是状态0到状态`<1,2>`的weight是最短的1，然后我们在合并后的状态`<1,2>`里记录剩下的(remaining)的权重，记为`<(1,0), (2,1)>`。它的意思是进入状态1之后剩下的权重就是0了，而如果进入的是状态2，那么剩余的权重是1。接下来我们发现左图状态1和2都可以进入状态3，`1->3`的权重是5，`2->3`的权重是6，因此合并后的状态`<(1,0), (2,1)>`可以进入状态`<(3,0)>`。`1->3`的权重是5，而1的剩余权重是0，所以最终权重是`5+0=5`；而`2->3`的权重是6，2的剩余权重是1，因此最终的权重是`6+1=7`。


##### 1.2.5 最小化(Minimization)操作

和DFA一样，WFST也可以通过Minimiaztion来进一步压缩空间和提高识别速度。通过把label和weight对(a, w)都看成字符串，我们可以把一个加权的FST/FSA看成一个普通的FST/FSA。比如下图(a)中，我们可以把”a/0”看成一个普通的label，然后使用普通的FSA的Minimization算法。

但是图(a)所示的WFST如果通过上面的方法进行Minimization之后仍然不变，因为所有的label都是不同的。但是我们可以通过weight pushing的方法进一步Minimization。


如下图(b)所示，我们可以把(a)的WFST的weight 往前pushing。我们把e/4和f/5的weight往前pushing到d/0和e/1中，这样状态1和2就可以合并成一个了，如图(c)所示。

<div align=center>
    <img src="zh-cn/img/ch17/p15.png"   /> 
</div> <p align=center>WFSA Minimization示例</p>

weight pushing是一种特殊的reweighting，我们下面用tropical 半环为例来说明reweighting，其它半环是类似的。关于半环(semi-ring)后面会有介绍，读者暂时不用管它。

一个WFSA可以有无穷多种reweighting的方式而且保证reweighting之后的WFSA是等价的。为什么有无穷多种呢？比如i是WFSA A的初始状态，f是A的终止状态(因为任何一个WFSA有一个等价的WFSA，这个WFSA只有一个终止状态)。函数`V:Q→R`是一个势(potential)函数，它把状态映射成一个数值。假设t是一个跳转(边)，`w[t]`是它的weight，`p[t]`是边的起点，`n[t]`是边的终点。那么我们可以把原理的`w[t]`通过势函数修改为：

$$w[t] \leftarrow w[t] + (V(n[t]) - V(p[t]))$$

同时把终止状态的weight改成:$\rho[f] \leftarrow \rho[f] + (V(i) - V(f))$

如果我们考虑一条从初始状态i到终止状态f的路径：
$$i \overset{t_1}{\rightarrow} v_1 \overset{t_2}{\rightarrow} v_2 \overset{t_3}{\rightarrow} f$$
原来的weight是：
$$\rho[i] + w[t_1] + w[t_2] + w[t_3] + \rho[f]$$

而reweighting之后为：
$$\rho[i]  + w[t_1] +(V(v_1)-V(i) + w[t_2] +(V(v_2)-V(v_1)) + \\
 w[t_3]+(V(f)-V(v_2)) + \rho[f] +(V(i) -V(f)) $$
$$= \rho[i] + w[t_1] + w[t_2] + w[t_3] + \rho[f] +[V(v_1)-V(i)+V(v_2)-V(v_1)+V(f)-V(v_2)+V(i)-V(f)] $$
$$ = \rho[i] + w[t_1] + w[t_2] + w[t_3] + \rho[f]$$


##### 1.2.6 算法实现

WFST的Composition、Determinization和Minimization的具体算法这里就不详细介绍，有兴趣的读者可以阅读[Speech Recognition with Weighted Finite State Transducers](https://cs.nyu.edu/~mohri/pub/hbka.pdf)等相关论文。我们通常也不需要自己实现这些算法，[OpenFst](https://www.openfst.org/twiki/bin/view/FST/WebHome)等开源库提供了高效的实现，而语音识别工具[Kaldi](http://kaldi-asr.org/)更是对OpenFst进行了封装，使得它更加适合语音识别的任务。


##### 1.2.7 半环和WFST的形式化定义

前面通过非形式化的方式介绍了WFST，下面我们形式化的定义WFST，但是先要了解一下半环的概念。这是属于抽象代数(计算机的离散数学课程可能会介绍)，不感兴趣的读者可以跳过。

之前提到过，WFST的路径上的权值需要通过两个操作“整合”起来，这两个操作在权重(实数集合)上就构成了一个半环(semiring)，我们我们来正式的定义半环。

半环是一个五元组$(\mathbb{K}, \bigoplus, \bigotimes, \bar{0}, \bar{1})$，其中$\mathbb{K}$是一个集合，比如实数集合$\mathbb{R}$，$\bigoplus$和$\bigotimes$是定义在$\mathbb{K}$上的二元函数，分别叫做“加法”和“乘法”，注意这个两个函数不(一定就)是我们学过的加法和乘法，但是它和实数集上的加法以及乘法有类似的结构，所以我们把它们也叫做加法和乘法，但是记号上用一个圈区别一下。 $\bar{0}$和$\bar{1}$是属于$\mathbb{K}$的两个特殊元素，分别叫做加法单位元和乘法单位元，因为它们和实数中的0和1有类似的性质，因此也叫零元和幺元。如果满足如下条件，那么这个五元组就是一个半环：

+ 加法满足交换律和结合律

也就是$\forall x,y\;$，有：

$$x \bigoplus y = y \bigoplus x$$
$$(x \bigoplus y) \bigoplus z = x \bigoplus (y \bigoplus z)$$


+ 零元加任何元素不变

$$\bar{0} \bigoplus x =x \bigoplus \bar{0} =x$$

+ 乘法满足结合律和对加法的分配率

$$(x \bigotimes y) \bigotimes z = x \bigotimes (y \bigotimes z)$$
$$(x \bigoplus y) \bigotimes z= x \bigotimes z \bigoplus y \bigotimes z$$
$$x \bigotimes (y \bigoplus z)= x \bigotimes y \bigoplus x \bigotimes z$$

+ 零元乘以数也不变

$$\bar{1} \bigotimes x=x \bigotimes \bar{1}=x$$


+ 零元乘以任何数等于零(吸收律)

$$\bar{0} \bigotimes x =x \bigotimes \bar{0} = \bar{0}$$


如果乘法满足交换律，那么这个半环叫交换半环。我们之后讨论的半环都是交换半环。 实数上的加法和乘法是个半环，不过我们这里用不到，下面介绍几个WFST里可能用到的半环：

<div align=center>
    <img src="zh-cn/img/ch17/p16.png"   /> 
</div> 

其中$x \bigoplus_{log} y \equiv -log(e^{-x}+e^{-y})$,我们验证一下热带半环确实是一个半环。

+ 加法满足交换律和结合律

$$ x \bigoplus y = min(x,y)=min(y,x)=y \bigoplus x $$
$$ (x \bigoplus y) \bigoplus z=min(min(x,y),z)=min(x,min(y,z))=x \bigoplus (y \bigoplus z) $$

+ 零元加任何元素不变

$$\bar{0} \bigoplus x = min(+\infty,x)=x$$


+ 乘法满足结合律和对加法的分配率

$$(x \bigotimes y) \bigotimes z = (x+y)+z=x+(y+z)=x \bigotimes (y \bigotimes z) $$
$$ (x \bigoplus y) \bigotimes z = min(x,y) + z = min(x+z, y+z)=(x \bigotimes z) \bigoplus (y \bigotimes z)$$

+ 零元乘以数也不变

$$\bar{1} \bigotimes x=0 + x=x$$


+ 零元乘以任何数等于零(吸收律)

$$\bar{0} \bigotimes x =+\infty + x =+\infty = \bar{0}$$

因此热带半环确实是一个半环。有了半环的定义之后，我们现在可以形式化的定义WFST。

半环$\mathbb{K}$之上的一个weighted finite-state transducer(加权有效状态转录机, WFST)

$$T=(\mathcal{A}, \mathcal{B}, Q, I, F, E, \lambda, \rho)$$包括如下部分。

+ $\mathcal{A}$是一个有限的输入字母表
+ $\mathcal{B}$是一个有限的输出字母表
+ $\mathcal{Q}$是一个有限的状态集合
+ $I \subseteq Q$是初始状态集合
+ $F \subseteq Q$是终止状态集合
+ $E \subseteq Q \times (\mathcal{A} \cup {\epsilon}) \times (\mathcal{B} \cup {\epsilon}) \times \mathbb{K} \times Q$
+ $\lambda : I \rightarrow \mathbb{K}$，给初始状态一个weight
+ $\rho: F \rightarrow \mathbb{K}$，给终止状态一个weight

另外我们用记号$E(q)$表示离开状态$q$的所有转移(边)，而$|T|$表示$T$中所有状态和边的个数总和。给定一个转移e，`p[e]`表示起点(状态)， `n[e]`表示终点(状态)，`i[e]`表示输入字母，`o[e]`表示输出字母，`w[e]`表示权重。一条路径$π=e_1…e_k$是一连串的边，并且前后两条边的点是连接在一起的(也就是说后一条边的起点是前一条边的终点)，即$n[e_{i−1}]=p[e_i],i=2,3,…,k$。如果一条路径的开始状态和状态是同一个状态，那么这条路径就是一个cycle，即$p[e_1]=n[e_k]$。如果一个cycle的所有边的输入和输出符号都是ϵ，那么这个cycle就叫ϵ−cycle。

我们也可以把函数$n,p$和$w$从边扩展到路径上,$n(\pi)=n(e_k),p(\pi)=p(e_1)$,$w[\pi]=w[e_1] \bigotimes … \bigotimes w[e_k]$。

接着我们可以形式化的定义WFST的composition，假设$T_1$和$T_2$是两个WFST，其中$T_1$的输入字母表是$\mathcal{A}$，输出字母表是$\mathcal{B}$；而$T_2$的输入字母表是$\mathcal{B}$，输出字母表是$\mathcal{C}$。则$T_1$和$T_2$的composition定义为：
$$T_1 \circ T_2(x, y) = \underset{z \in \mathcal{B}^*}{\bigoplus}T_1(x,z) \bigotimes T_2(z,y)$$


#### 1.3 WFST在语音识别中的应用

前面介绍了WFST的基本原理和一些常见操作，下面我们介绍WFST在语音识别中的应用。我们回顾一下，一个WFST定义了一个关系(而不是一个函数)，它的输入是一个字母表上的字符串，而输出是另一个字母表上的多个(或者零个)字符串以及对应的概率。我们可以把它看成一个一对多的”函数”，输入一个字符串，输出多个字符串及其概率。

我们可以把语音识别的组件都用WFST来表示，而它们的组合使用WFST的composition来表示。在语音识别中有4个WFST transducer，我们下面逐个介绍。


##### 1.3.1 G


G表示语言模型。它是一个WFSA，它的输入是一个词序列，然后G可以判断这个词序列是否符合语法以及它的概率。对于固定的文法来说，它只能识别符合文法的句子；而对于N-Gram来说，所有的句子都是可能的，只不过概率有高有低。

比如下图的WFSA它接受的语法只能识别”jim read”、”jim wrote”、”jim fled”等9个句子。


<div align=center>
    <img src="zh-cn/img/ch17/p17.png"   /> 
</div> <p align=center>表示G的WFSA</p>


##### 1.3.2 L

L是发音词典。它的输入(上下文无关的)音子序列，输出是词序列。比如上面文法对应的发音词典：

```
bill b ih l
jill jh ih l
jim jh ih m
read r eh d
read r iy d
red r eh d
...
```

注意：read有两种发音`/r eh d/`和`/r iy d/`，这当然没有什么问题。但是如果两个词有相同的发音就会有问题，比如read和red都可以发音成`/r eh d/`，我们后面会介绍怎么解决不同词有相同发音的问题。

我们可以根据这个发音词典构造L，如下图所示。这个WFST的输入可以是词典里任意词的音子的序列，而输出是词的序列，比如输入是`”b ih l b ih l b ih l”`，那么输出就是`”bill bill bill”`，当然这并不符合G的文法，但这没关系，我们后面把它们进行composition之后，也就是`L∘G`，它就只能输出符合G文法的句子了。

<div align=center>
    <img src="zh-cn/img/ch17/p18.png"   /> 
</div> <p align=center>表示L的WFSA</p>

那这个L是怎么构造出来的呢？我们先假设不同的词的发音都不相同的情况。那么很简单，我们构造一个初始状态(30)，然后构造一个状态0，初始状态可以通过ϵ跳转到0，然后词典里的每个词都展开成一个状态链条。比如`”bill b ih l”`，我们把3个因子`[b ih l]`分别构造`3`个状态和`3`条边：

$$0-(b:bill)->1，1-(ih:\epsilon)->2，2-(l:\epsilon)->3$$

注意，第一条边就输出了单词bill，而后面的边输出的是ϵ。最后我们再加一条特殊的边来表示单词的结束：`3-(\# 1:ϵ)->4`

状态4是接受状态，这样就可以识别一个单词，为了识别多个单词，我们需要在每个单词的接受状态通过ϵ跳转又调回到状态0。

注意，这个WFST是非确定性的。比如输入是`[jh il m]`，状态0有两条边可以输入`jh(jim和jill)`，因此我们同时进入状态10和14，接着输入`il`，状态机进入11和15。接着输入`m`，状态11无法处理，直接”死掉”，而状态15输入`m`后进入状态16，接着输入特殊的`#0`(我们后面会讨论)，然后进入状态17，这是一个接受状态。如果后面再没有输入了，那么WFST的输出就是单词jim。如果后面还有`”f l eh d #0”`，那么它就通过ϵ跳转到状态0，然后识别`”f l eh d #0”`，最终进入状态9，这也是一个接受状态。如果后面再没有输入，WFST就输出`”jim fled”`。

非确定性的WFST是比较容易构造的(类似于NFA比DFA容易构造一样)，但是识别的时候需要递归或者回溯，因此效率较低，我们可以把它转换成等价的确定性WFST。前面的假设是所有的单词的发音都不相同，因此(可能但也并一定)存在一个与之等价的确定性的WFST。但是如果两个单词的发音完全相同，比如read和red的发音都是`/r eh d/`，那么显然不可能存在等价的确定性的WFST。那怎么办呢？假设最多`k`个不同的词有相同的发音，我们可以引入特殊的消歧符号`#0、#1…#(k-1)`。我们在发音词典的每一个词后面都加一个消歧符号，比如：

```
read r eh d #0
red r eh d #1
```


##### 1.3.3 C


C 是把上下文相关的音子序列转换成上下文无关的音子序列的WFST。声学模型的输出是上下文相关的音子序列，而L要求的输入是上下文无关的音子序列，因此我们需要C来把上下文相关的音子序列转换成上下文无关的。

比如下图所示的发音词典，为了更好的效果，我们需要使用上下文相关的音子，比如`ae/k_t`表示当前的音子是`ae`而它的上一个音子是`k`而下一个音子是`t`。

<div align=center>
    <img src="zh-cn/img/ch17/p19.png"   /> 
</div> <p align=center>示例发音词典</p>


下图是一个示例。图(a)是非确定的WFST；而图(b)是确定的WFST。


<div align=center>
    <img src="zh-cn/img/ch17/p20.png"   /> 
</div> <p align=center>表示C的WFST</p>


我们先看图(a)，状态`”k,ae”`表示当前音子是`k`而下一个音子是`ae`(这类似与NFA的猜测)，这个状态下只能输入`ae`。当输入`ae`之后进入状态`”ae,t”`，表示新的当前音子是`ae`而下一个音子是`t`(猜测)。因此如果下一个输入不是`t`的话，这个猜测分支就会”死掉”，不过这没有关系，会有别的分支来正确的识别。

比如输入如果是`[“k”, “ae”, “t”]`的话，初始状态是`”eps, eps”`，表示当前音子是空(什么也不是)，下一个是`*`(表示所有可能)。遇到输入`k`就进入状态`”k,ae”`并且输出`”k/eps_ae”`，接着遇到`ae`就进入状态`”ae,t”`并且输出`”ae/k_t”`，接着遇到`t`就进入状态`”t, eps”`并且输出`”t/ae_eps“`，这是一个接受状态，因此最终它把上下文无关的音子序列`[k ae t]`转换成上下文相关的序列`[k/eps_ae, ae/k_t, t/ae_eps]`。


但如果输入是`[“k”, “ae”, “f”]`，则上面的过程走到状态`”ae,t”`就走不下去的，但是另外一个识别`[“k”, “ae”, “f”]`的路径会成功识别并且把它转化成上下文相关的序列。


当然我们要的是把上下文相关的序列转换成上下文无关的序列，上面得到的是相反的WFST，这可以通过WFST的求逆运算把它反过来。

但是前面图(a)的WFST是非确定性的，我们可以采样图(b)的方式来把它变成确定性的。


在图(b)中，状态`”k,ae”`表示当前音子是`ae`而前一个音子是`k`，这和之前是不同的，之前状态`”k,ae”`表示当前状态是`k`而下一个音子是ae！

在图(a)中，状态`”k,ae”`只能输入`”ae”`，因为它猜测`k`后面是`ae`，而图(b)中`”k,ae”`可以输入很多个，比如：

```
"k,ae" -t-> ae/k_t
"k,ae" -d-> ae/k_d
....
```

相对于图(a)，图(b)的输出有一个时刻的延迟，比如图中输入`t`的时候输出的是前一个音子`ae`的结果`”ae/k_t”`，因此需要在最后加一个特殊的结束符号以便输出最后一个音子的结果。


##### 1.3.4 H

H是把声学观察序列变成上下文相关音子序列的WFST。这个WFST代表声学模型，它的输入是观察序列，输出是上下文相关音子序列及其概率。

最终我们可以把这4个WFST用composition操作组合起来得到`H∘C∘L∘G`，这个大的WFST的输入是观察序列，而输出就是词序列，我们通过搜索最短路径(因为是热带半环，-log概率，因此最短路径等价与最大概率)来找到最可能的路径，也就是实现了解码算法。


不过为了使WFST能够变成确定的，我们需要对H、C和L做一些特殊处理，包括加入消歧符号和self-loop等操作，具体细节这里就不介绍，有兴趣的读者可以参考相关论文。最终我们得到$\tilde{H} \circ \tilde{C} \circ \tilde{L} \circ G$，我们是把它们composite起来得到$\tilde{H} \circ \tilde{C} \circ \tilde{L} \circ G$。这个WFST不是确定的，因此我们需要把它变成确定的并且变成最小的WFST，当然这有很多方法，最常见的就是：

$$N=\pi_\epsilon(min(det(\tilde{H} \circ det(\tilde{C} \circ det(\tilde{L} \circ G)))))$$


### 2.WFST介绍


下面将形式化的定义WFST和基于自动机理论介绍它的基本属性。然后会介绍一些用于构建和优化语音识别网络的重要操作(operation)

#### 2.1 有穷自动机(Finite Automata)

WFST是一种有穷自动机(FA)。一个有穷自动机有一个有限的状态集合以及状态之间的跳转，其中每个跳转至少有一个标签(label)。最基本的FA是有限状态接收机(finite state acceptor/FSA)。giddy一个输入符号序列，FSA返回”接受”或者”不接受”，它的判断条件是：如果存在一条从初始状态到终止状态的路径，使得路径上的标签序列正好等于输入符号序列，那么就是”接受”，否则就是”不接受”。

下图(a)是一个FSA的例子，图中的节点和边分布代表状态和状态之间的跳转。比如这个FSA接受在符号序列”a,b,c,d”，因为状态跳转序列”0,1,1,2,5”是从初始状态到最终状态的路径，它的边对应的符号序列正好是”a,b,c,d”。但是它不能接受”a,b,d”，因为无法找到满足条件的状态序列。因此，一个FSA代表了它能接受的符号序列的集合。符号序列也被成为字符串。图(a)的FSA代表的字符串集合等价于正则表达式`”ab∗cd|bcd∗e”`。我们这里假设状态0是初始状态而5是终止状态。如果没有特殊说明，我们用加粗的圆圈表示初始状态，用两个圈表示终止状态。

<div align=center>
    <img src="zh-cn/img/ch17/p21.png"   /> 
</div> <p align=center>有穷自动机示例</p>

接下来我们介绍几种FSA的扩展，这里我们之后介绍有限状态转录机(Finite-State Transducer/FST)，加权有限状态接收机(Weighted Finite-State Acceptor/WFSA)和加权有限状态转录机(Weighted Finite-State Transducer/WFST)。这些FA继承了FSA的基本特性，但是它们的输出不只是一个二值的”接受/不接受”，而是会输出另一个符号序列(FST)，一个权值(WFSA)或者同时输出一个新的符号序列和权值(WFST)。

FST的每个跳转(边)上都有一个输出符号，因此它的边上是一个输入标签和输出标签的pair。上图(b)中就是一个FST的例子。在图中用`”输入符号:输出符号”`来表示。通过这个扩展，FST描述了把一个输入符号序列转换为另一个输出符号的转换规则。例子中的FST可以把输入符号序列”a,b,c,d”转换成”z,y,x,w”。

WFSA的每个跳转除了输入符号还有一个weight，此外初始状态和终止状态也有对应的初始weight和终止weight。weight通常代码跳转的概率或者代价，不同的路径上的weight会通过”乘法”来累计。因此，WFSA提供了一种比较不同路径的度量(measure)。上图(c)是一个WFSA的例子。在上图中，每条边为”输入标签/weight”，并且初始状态表示为”初始状态ID/weight”；终止状态表示为”终止状态ID/weight”。对于这个WFSA，它接受序列”a,b,c,d”并且累计的weight是0.252：路径是0,1,1,2,5，weight为`0.5 × 1.2 × 0.7 × 3 × 2 × 0.1`。

WFST的跳转上同时包括输出标签和weight，因此WFST可以认为是FST和WFSA的组合。上图(d)是一个WFST的例子，图中的边上为”输入符号:输出符号/weight”。初始和终止的weight也在对应的状态上标识出来。这这个WFST里，它可以把输入符号序列”a,b,c,d”变成”z,y,x,w”，并且weight是0.252。

weight元素的集合$\mathbb{K}$上的一个WFST由下面的8-tuple `(Σ,Δ,Q,I,F,E,λ,ρ)`来定义：
+ Σ是一个有限的输入符号集合
+ Δ是一个有限的输出符号集合
+ Q是一个有限的状态集合
+ I⊆Q是初始状态集合
+ F⊆Q是终止状态集合
+ $E \subseteq Q \times (\Sigma \cup { \epsilon }) \times (\Delta \cup { \epsilon }) \times \mathbb{K} \times Q$ 跳转的多重集合
+ $\lambda : I \rightarrow \mathbb{K}$是初始状态weight的函数
+ $\rho : F \rightarrow \mathbb{K}$是终止状态weight的函数

ϵ是一个特殊的(输入和输出)符号，它代表空，没有输入/输出。上图(d)的WFST为：

+ $\Sigma = \{a,b,c,d,e\}$
+ $\Delta = \{v,x,y,w,z\}$
+ $Q=\{0,1,2,3,4,5\}$
+ $I=\{0\}$
+ $F=\{5\}$
+ E={(0,a,z,1.2,1), (0,b,y,0.8,3), (1,b,y,0.7,1), (1,c,x,3,2), (2,d,w,2,5), (3,c,x,0.2,4), (4,d,w,1.2,4), (4,e,v,0.6,5)}
+ $\lambda(0)=0.5$
+ $\rho(5)=0.1$

E中的每一个跳转为(源状态, 输入符号, 输出符号, weight, 目标状态)。其它的FA，包括FSA、FST和WFSA，都可以看成WFST的特殊情况。

另外一种FA的扩展方式是把跳转的输入/输出符号变成一个输入/输出字符串(一个字符串是多个符号)。不过本文不会考虑这种情况。事实上，基于字符串的FA可以转换成与之等价的基于单个符号的FA。

最后，我们用下表来总结4种类型的FA。如上面提到过的，FSA的跳转上只有一个输入符号并且最终返回是否接受某个输入符号序列。在下表里，”function”表示这个FA表示的映射(mapping)。对于FSA来说，$\Sigma^*$里的一个输入符号序列被映射为二值0,1，其中0表示接受1表示拒绝。FST的跳转上同时有输入和输出符号，它表示的映射是一个函数$f: \Sigma^* \rightarrow 2^{\Delta^*}$，这里$2^{\Delta^*}$表示$\Delta^*$的幂集。它表示FST可以把同一个输入字符串(符号序列)映射为多个(当然也包括零个)输出符号序列。WFSA的跳转上有一个weight，它表示的映射为$f:\Sigma^* \rightarrow \mathbb{K}$，也就是把一个输入字符串映射为$\mathbb{K}$里的一个元素(数)。而WFST是WFSA和FST的组合，它把一个输入字符串映射为一个集合，集合中的每个元素包括一个输出字符串和一个weight。


<div align=center>
    <img src="zh-cn/img/ch17/p22.png"   /> 
</div> <p align=center>4种FA的对比</p>

请读者注意这几个缩写：FA指的是Finite Automata，它是一个最大的概念，它包括下面的所有自动机；FSA，Finite State Acceptor；WFSA，Weighted FSA；FST，有限状态转换机；WFST，Weighted FST。另外我们有时会用缩写DFA和NFA，它指的是确定的FA和不确定的FA，一般如果不做明确说明分别指的是确定的FSA和不确定的FSA。

#### 2.2 FA的基本属性

FA的一个重要性质是它是确定的(deterministic)还是非确定的(non-deterministic)。一个确定的FA(DFA)只有一个初始状态，并且对于每个状态如果给定了一个输入符号，最多有一条边。因此如果某个输入符号序列是被它接受的，也只有一条对应的从初始状态到终止状态的路径。DFA的优点是给定输入符号序列，判断它是否被接受的计算是比较快的(相对于非确定的NFA来说)。如果我们使用二分查找来获得一个输入符号的边的话，DFA的计算复杂度是$O(L log_2 \hat{D})$。这里L是输入符号序列的长度，D是从一个状态跳出的边的最大数量。这个计算复杂度适合长度L成线性比例关系的，但是和$\hat{D}$对数的关系，也就是说$\hat{D}$的成倍增长不会引起复杂度的成倍增长

而NFA给定一个状态和一个输入符号，它可以有多条跳转的边。因此，我们需要考虑多种可能的路径。虽然NFA的计算复杂度依赖于它的结构，在最坏的情况下的复杂度是`O(L×|Q|×|E|)`。不过存在一个算法把NFA转换成与之等价的DFA。这叫做确定化(determinization)算法。确定化之后，NFA的功能可以由与之等价的计算量更少的DFA来实现。下图的NFA和DFA是等价的。注意：虽然所有的FSA可以确定化，但是对于其它的FA，比如FST、WFSA和WFST不一定存在与之等价的确定化的FA。

<div align=center>
    <img src="zh-cn/img/ch17/p23.png"   /> 
</div> <p align=center>NFA和等价的DFA</p>

转换机(FST和WFST)是sequential当且仅当在我们只考虑输入符号的时候它是确定的。另外，转换机是函数的(functional)当且仅当对于任意一个输入符号序列，最多有一个输出符号序列(当然可以没有)与之对应。函数的转换机是可以确定化的，这里我们不做证明。下图展示了一些FST。

<div align=center>
    <img src="zh-cn/img/ch17/p24.png"   /> 
</div> <p align=center>不同属性的FST</p>

图(a)是函数的FST；图(b)是它确定化后的等价的sequential的FST。注意：图(a)不是sequential的，因为在状态1的时候输入符号是a的边有两条；但是它是函数的，因为对于任何一个输入字符串，最多有一个输出字符串。

图(c)是非函数的FST，因为给定输入字符串”ab”，输出有两个字符串”uv”和”uw”。如果只考虑输入符号，它是可以确定化的；但是如果考虑输出符号，则它因为输出符号的歧义而不能确定化。在这种情况下，它的确定化会得到p-subsequential的FST，如图(d)所示，这是一种更加一般的sequential FST。p-subsequential的FST允许它的终止状态有p个带标签的跳转(这些边只有起点没有终点)。不过本文不讨论这种定义，它可以表示为等价的FST，如图(e)所示。通过在原来的终止状态后面引入ϵ的跳转和新的终止状态来实现。

FA的另外一个重要属性就是它的输入标签里是否有特殊的ε。输入符号为ε的跳转叫做ε-跳转，这个状态的跳转不需要任何输入符号就可以进行。下图(a)是一个包含ε-跳转的FSA。这个FSA首先在状态0通过输入符号”a”或者”b”跳转到状态1。因为状态1和2之间有一个ε-跳转，因此它可以在不读入任何输入符号的条件下跳转到状态2，当然在没有任何输入的时候它也可以还是呆在状态1。因此这FSA可以同时呆在状态1和2。因此有ε-跳转的FSA是非确定的，我们把它叫做ε-NFA。

存在一个算法(ε-消除算法)把一个ε-NFA转换成与之等价的没有ε-跳转的NFA。下图(b)是与(a)等价的没有ε-跳转的NFA。

<div align=center>
    <img src="zh-cn/img/ch17/p25.png"   /> 
</div> <p align=center>ε-NFA和没有ε的NFA</p>

最后，给定一个FA，我们把所有与之等价的DFA组成的集合里状态数最小的DFA叫做最小DFA。下图(a)是一个DFA，图(b)是与之等价的最小DFA。最小DFA也可以用于检查不同的FA是否等价，因为两个FA通过消除ε跳转、确定化和最小化之后，如果它们是等价的，则经过上述3个操作之后得到的最小DFA是完全一样的(状态和跳转完全一样，当然可能是状态的命名不一样)。

<div align=center>
    <img src="zh-cn/img/ch17/p26.png"   /> 
</div> <p align=center>DFA和与之等价的最小DFA</p>


#### 2.3 基本运算

这里，我们回顾一些FA(而不仅仅是WFST)上的一些一元和二元操作。我们已经介绍过一个FA代表了从一个输入符号序列到weight或/和一个输出符号序列的映射。这些基本的操作是通过增加或者删除跳转并且和其它的FA的组合(combining)来扩展实现的。

在自动机理论里，Kleene闭包(closure)、并(union)和连接(concatenation)是所有的FA都有的三种常见运算。Kleene闭包让一个FA接受的字符串是原来自动机接受的字符串的零次或者多次重复。给定一个自动机A，它的Kleene闭包被记作$A^*$。两个FA的并是它们能接受的字符串集合的并集。而两个FA的连接则是这样的字符串集合：它是两个字符串的连接，并且第一个字符串来自第一个FA；第二个字符串来自第二个FA。

给定两个自动机A1和A2，它们的并记作`A1∪A2`或者`A1+A2`，它们的连接记作`A1⋅A2`或者`A1×A2`。下图(a)和(b)分别是两个WFST TA和TB。图(c)是WFST TA的Kleene闭包$T_A^*$，要实现Kleene闭包，我们首先增加一个新的初始状态，然后让它以一个ε-跳转到原来的初始状态(原来的初始状态现在就不是初始状态了)并且把原来的初始weight移到这条边上，然后在原来的终止状态增加一个空的跳转到原来的初始状态(注意不是新的初始状态，否则weight会有问题)。图(d)是`TA∪TB`，实现的的方法为：新建一个新的初始状态，然后用ε-跳转分别跳到原来TA和TB的初始状态(在TA∪TB里原来TA和TB的初始状态不再是初始状态，并且它们的初始weight移到这条边上了)。图(e)是`A1⋅A2`，实现的方法为：在TA的每一个终止状态都新加一个ε-跳转到TB的每一个初始状态，并且把TB的终止状态的weight和TA的初始状态的weight都移到这条边上，然后把TA的终止状态变成普通的状态，把TB的初始状态变成普通的状态。

<div align=center>
    <img src="zh-cn/img/ch17/p27.png"   /> 
</div> <p align=center>自动机的基本运算</p>

对于转换机(FST和WFST)，投影(projection)、反转(inversion)和复合(composition)是比较重要的运算。投影是通过去掉输出符号把一个转换机变成一个接收机。反转是把转换机的输入和输出反过来。下图是对WFST TA的投影和反转。投影时直接把输出符号去掉就行；而反转则是把边的输入和输出符号交换一下，其余的都不变。

<div align=center>
    <img src="zh-cn/img/ch17/p28.png"   /> 
</div> <p align=center>投影和反转</p>

#### 2.4 转换机(transducer)的复合

在介绍复合之前我们先介绍几个术语

给定一个WFST T=(Σ,Δ,Q,I,F,E,λ,ρ)，对于任何的q∈Q，我们把从q出去的边组成的多重集合(所谓多重集合指的是其元素可以重复)记作$E[q]$。对于任意的e∈E，我们把跳转的输入符号记作$i[e]$，输出符号记作$o[e]$，起点(边的出发状态)记作$p[e]$，终点记作$n[e]$，weight记作$w[e]$。一条路径可以用跳转的序列来表示为$\pi=e_1,…,e_k$，其中满足后一条边的起点是前一条边的终点，亦即$n[e_{j-1}]=p[e_j], j=2,…,k$。此外我们把这些记号扩展到路径，把路径的起点记为$p[π]$，路径的终点记为$n[π]$。路径的输入字符串记为$i[π]$，其中$i[\pi]=i[e_1] \cdot \cdot \cdot i[e_k]$。类似的输出字符串记为$o[π]$，其中$o[\pi]=o[e_1] \cdot \cdot \cdot o[e_k]$。$w[\pi]=w[e_1] \bigotimes \cdot \cdot \cdot \bigotimes w[e_k]$。如果$p[e_1] \in I$(路径的起点是初始状态)并且$n[e_k] \in F$，则这条路径叫做一条成功的路径。如果一个状态(点)可以从(某个)初始状态走到这里并且也可以从这个点走到(某个)终止状态，则这个状态成为coaccessible。coaccessible的状态至少在一条成功的路径上(因为可以从初始状态走到它然后又可以从它走到终止状态，显然只是一条成功的路径)。非coaccessible的状态被成为死(dead)状态。类似的，跳转(边)也分为coaccessible和非coaccessible。删除一个FA的非coaccessible的点和边的操作叫做trimming，没有死状态和死跳转的FA叫做trimmed的FA。一个FA进行trimming之后得到的FA就是trimmed的FA。

下面我们来介绍复合算法的基本原理。下图(a)是一个转换机，它的作用是把输入字符串所有的字符都变成大写；图(b)只识别(接受)”RED”、”BLUE”和”GREEN”三个词(字符串)。它们复合后的结果如图(c)所示，这个复合后的FST的作用是识别各种大小写组合的这3个词(比如”REd”、”BluE”)。有的时候设计一个FST是比较复杂的，但是通过把它分解为多个FST的复合会变得容易得多。

<div align=center>
    <img src="zh-cn/img/ch17/p29.png"   /> 
</div> <p align=center>复合操作</p>

下面的算法10是没有ε的WFST复合算法，它要求第一个转换机的输出符号不包含ε并且第二个转换机的输入符号也不包含ε。等下我们会介绍更加通用的能处理ε的算法。

<div align=center>
    <img src="zh-cn/img/ch17/p30.png"   /> 
</div> <p align=center>没有ε的复合算法</p>

在上面的算法里，$T_1=(\Sigma_1, \Delta_1, Q_1, I_1, F_1, E_1, \lambda_1, \rho_1)$，$T_2=(\Sigma_2, \Delta_2, Q_2, I_2, F_2, E_2, \lambda_2, \rho_2)$。复合后的WFST的状态是T1和T2的状态对组成。因此复活后的状态用原来状态对`(q1,q2)`来表示，其中`q1∈Q1`并且`q2∈Q2`。从复合状态`(q1,q2)`出去的跳转也是`e1`和`e2`的组合，其中`e1∈E[q1]、e2∈E[q2]`并且`o[e1]=i[e2]≠ϵ`。这会产生一个复合后的WFST的一个跳转，这条边的起点是`(q1,q2)`，终点是`(n[e1],n[e2])`，输入符号是`i[e1]`，输出符号是`o[e2]`，weight是`w[e1]⨂w[e2]`。这样的话，T相对于是T1和T2的级联。这个算法的复杂度是`O(|T1||T2|)`，其中`|T1|=|Q1|+|E1|`，也就是点的个数加边的条数。

在上面的算法里，第1-4行是处理复合后的初始状态，它是直接通过`I1`和`I2`的笛卡尔积计算得到。初始状态`(i1,i2)`的weight是`λ(i1)⨂λ(i2)`。然后在第5行把所有的初始状态都插入到状态队列Q和未处理(待处理)队列S里。接下来就是一个大的循环处理S中的状态`(q1,q2)`直到S为空。在第9-12行，如果q1和q2分别是T1和T2的终止状态，则`(q1,q2)`是复合后的终止状态，需要把它加到F，而它的weight为`ρ(q1)⨂ρ(q2)`。第13-19行，我们遍历q1的出边e1和q2的出边e2的所有组合，如果e1的输出符号`o[e1]`等于e2的输入符号`i[e2]`，则它们可以产生一条新的边。这条新边的起点是`(q1,q2)`、终点是`(n[e1],n[e2])`(`n[e_1]`是边e1指向的状态)、输入符号是`i[e1]`、输出符号是`o[e2]`、weight是`w[e1]⨂w[e2]`。我们需要把这条边加到复合后的WFST的跳转集合E里。如果新的状态`(n[e1],n[e2])`之前没有处理过，也需要加到S和Q里。因为E是一个多重集合(multi-set)，相同的跳转(起点和终点相同并且输入和输出符号也相同，weight可以不同)可以会出现多次。

上面的算法假设T1的边输出符号不是ε并且T2的输入符号也不是ε。对于更通用的复合算法，我们需要小心的处理ε，从而通过模拟ε-跳转得到扩展的算法。这个扩展算法可以使用FST的操作来解释。如下图所示，图(a)和(b)是待复合的WFST，其中图(a)的输出符号包含ε，图(b)的输入符号包含ε。图(a)把输入字符串”abc”转换成”ef”；而图(b)把输入字符串”ef”转换成”ABCD”。所以复合后的WFST应该是把”abc”转换成”ABCD”。

<div align=center>
    <img src="zh-cn/img/ch17/p31.png"   /> 
</div> <p align=center>有ε的WFST以及对它进行修改以便复合操作</p>

为了进行复合，我们对T1和T2进行扩展。ε-跳转指定是自动机在没有输入的情况下就进行跳转。为了复合，我们需要考虑两种情况：T1的输出为ε；T2的输入为ε。

在第一种情况下，T1没有输出，因此只是T1发生了ε-跳转而T2的状态没有变化。而第二种情况下，T2在不需要输入的情况下发生跳转，因此T1不需要产生任何输出也就是T1的状态不发生变化。为了模拟这些跳转，我们在上图(c)和(d)中分别对T1和T2进行扩展。

做法是对于T1的每一个状态都增加输入是ε输出是εi的自跳转，它表示T1的状态不变，只是T2发生自跳转(自跳转的输入是εi)，另外需要把原来的输出从ε变成εo，以示区别。对于T2需要把原来的输入为ε的边改成输入为εi的边，这是和前面配合的，它表示T2进行空跳转，而T1不动；类似的需要给T2的每一状态都增加自跳转，输入为εo输出为ε。

把扩展后的$T_1’$和$T_2’$用前面的算法进行复合，就可以得到有ε的WFST的复合结果，如下图所示。

<div align=center>
    <img src="zh-cn/img/ch17/p32.png"   /> 
</div> <p align=center>$T_1 \circ T_2$</p>

我们来看`(1,1)->(1,2)`，T1的状态是从`1->1`，所以是经过边`1-ε:εi->1`；而T2的状态是从`1-εi:B->2`，所以复合后的边为`(1,1)-ε:B->(1,2)`。这是我们说的第一种情况：T1的状态不变而T2发生ε-跳转。类似的从`(1,1)->(2,1)`是第二种情况，请读者自己分析。

但是上图的WFST存在冗余的路径。此外，对于非幂等(non-idempotent)的半环比如概率和log半环，因为存在冗余路径，对于一个输入字符串：输出字符串对累加的weight也是不对的。为了解决这个问题，一种叫做filter的WFST被引入复合运算。假设F是一个filter，我们复合时计算的是$T_1’ \circ F \circ T_2’$而不是$T_1’ \circ T_2’$。比如下图(a)是一个两状态(也叫epsilon-sequencing)的filter，图中”x”表示$\Sigma_2 \cap \Delta_1$中的任一符号。

<div align=center>
    <img src="zh-cn/img/ch17/p33.png"   /> 
</div> <p align=center>复合用的filter</p>

我们可以这样来理解图(a)的这个filter，如果输入是普通的符号x，则输出x；假设当前在状态0，如果输入是εo，则输出也是εo，表示T1发生ε-跳转而T2状态不变；如果输入是εi，则输出是εi，并且跳到状态2，这个状态表示T2发生ε跳转而T1不动。这个filter会优先考虑T1状态变化的情况。$T_1’ \circ F \circ T_2’$得到的WFST如下图(a)所示，图中灰色的路径死掉的路径。在上面的复合中，类似于`(1,1)->(1,2)->(2,2)`这样的路径是不允许的。因为这条路径首先是T2发生εi的跳转(T1不动)，然后立刻是T1发生εo的跳转(T2不动)，而在这个filter里，经过εi之后状态跳到了1，而状态1是不允许εo的跳转的。通过这样的方法，我们可以去掉冗余的路径。当然图(a)复合的结果还有死掉的状态和跳转，我们需要去掉。

<div align=center>
    <img src="zh-cn/img/ch17/p34.png"   /> 
</div> <p align=center>$T_1’ \circ F \circ T_2’$</p>

另外，我们可以使用3-状态的filter(epsilon-matching filter)，如上图(b)所示，使用它计算$T_1’ \circ F \circ T_2’$的结果如上图(b)所示。3-状态的filter会尽量优先走`εo:εi`的边，也就是用T1的ε输出来驱动T2的ε输入。所以我们看到有从`(1,0,1)->(2,0,2)`的跳转，它不允许εi之后马上是εo的跳转(和前面的2-状态filter一样)，而且它也不允许εo之后马上是εi的跳转。因此我们看到`(1,0,1)->(2,2,1)`之后不能在跳到`(2,0,2)`，同样的`(1,0,1)->(1,1,2)`之后也不能跳到`(2,0,2)`。如果我们希望保留相同数目的ε，则应该使用2-状态的filter。否则应该使用3-状态的filter，因为它得到的WFST更加紧凑。


#### 2.5 优化运算

下面简要的介绍一些重要的优化运算，包括确定化(determinization)、weight pushing和最小化(minimization)。这些运算会把一个WFST转换成等价的WFST，但是这些优化后的WFST的执行速度更快并且运行时使用的内存也更少。

##### 2.5.1 确定化

确定化是FA最重要的优化运算。确定化是使用FA来解决序列识别和转换问题的重要优势，因为与原始FA等价的确定化的DFA的速度要比非确定的NFA要快得多。在设计一个FA来解决问题的时候，使用NFA通常更便于人理解(参考WFST简介·非确定有穷自动机)。但是从计算机运行的效率来说NFA通常比不上DFA。因此确定化在加速FA的执行方面是非常有用的。

前面提到过，给定一个状态和一个输入符号，DFA有且仅有一条跳出的边(有时为了简化会省略跳到死状态的边，但实际上DFA对于任何输入都是有边的)，因此如果DFA接受某个输入符号序列，则存在唯一的成功路径与之对应。寻找这条成功路径的时间复杂度是与序列的长度成正比，假设通过二叉树来存储每个状态的跳转，则每一步的复杂度是$log_2 \vert E(q) \vert$。

确定化的代码如下所示，它基本是和经典的FSA的确定化算法是一样的(参考WFST简介·通过子集构造把NFA转换成DFA)。在这个算法里，如果从一个状态遇到某一个输入符号有多条跳转，那么它们会被合并成一个跳转。多个跳转的终点状态也会被合并成一个新的状态。因此，在这个确定化后的FA里的一个状态是原来FA的状态的集合。当已经确定化的新状态给定一个输入符号时，这个状态对应的老状态的集合中的每一个都会尝试处理这个输入符号，然后把这些终点状态组成一个新的集合(新的状态)。通过这种方法，一开始的时候把所有原来FA的初始状态的集合当作新FA的初始状态，然后用上面的方法不断扩展得到新的状态，直到所有的新状态都处理完成为止。上面介绍的是NFA(非确定的有限状态接收机，其实应该简写为NFSA，但是很少有人这么简写)转换成DFA(确定的有限状态接收机)的算法。对于WFST，算法需要做一点扩展来支持输出符号和weight。粗略来讲，经典的确定化算法会使用输入符号来绑定跳转和终点状态。但是WFST的边上还有输出符号和weight。即使两个跳转的输入符号是相同的，它们的输出符号和weight也可能不相同。不同的输出符号和weight不能合并到通一个跳转上。因此在WFST的确定化算法里，不同跳转的输出字符串的公共前缀以及weight的和会放到新的跳转里。余下的输出字符和余下的weight会放到新状态里。因此，确定化的WFST的状态是一个三元组的集合，$\{(p, z, v) \vert p \in Q, z \in \Delta^*  , v \in K\}$，这里p是原始WFST的状态，z是余下的输出符号，v是余下的weight。为了能够确定化，半环需要是weakly left-divisible的，这样可以把weight的和除以每个跳转的weight。

<div align=center>
    <img src="zh-cn/img/ch17/p35.png"   /> 
</div> 

上面的算法会从原始的WFST `T=(Σ,Δ,Q,I,F,E,λ,ρ)`生成确定化的WFST` T′=(Σ,Δ,Q′,I′,F′,E′,λ′,ρ′)`。第1行代码生成`T’`的初始状态`i’`，`i’`是一个集合，这个集合的每一个元素都是三元组，`(i,ϵ,λ(i))`。前面我们介绍过了`T’`的每一个状态都是`(p, z, v)`这样的三元组，其中p是T里的状态，z是余下的输出符号，v是余下的weight。对于初始状态，p是T里的初始状态i，z是空，而v是初始状态的weight `λ(i)`。第2行把`i’`的weight设置为半环的幺元$\bar{1}$。第3行把初始状态加到集合`Q’`和S里，其中`Q’`是确定化后的WFST的状态集合，而S是待处理的新状态。

然后代码是一个大的while循环，处理S中的所有未处理状态，直到S为空。第5和6行从S里弹出一个带处理的新状态`p’`。

第7行遍历`p’`能处理的所有输入x。这一行有一些复杂，我们来详细阅读它。这一行为：`for each x∈{x|i[e]=x,e=E[p],p∈Q[p′]}`。用自然语言来描述就是：对于`p’`这个集合里的每一个原始状态p，我们遍历它的每一条边E[p]，然后找到这条边的输入符号i[e]为x。Q[p′]这个记号之前好像没有介绍过，我们来看一个例子。比如下图(b)的第二个状态`p′={(1,X,0),(2,Y,0.7)}`，则`Q[p′]`是`p’`中每个元素(是一个三元组)的第一个元素(来自T的状态)组成的集合。因此对于这个`p’`，`Q[p′]={1,2}`。而对于`p∈{1,2}`，我们可以遍历原始WFST的边(图a里)`1-b:ε->4、1-c:Z->5、2-b:ε->6`和`2-d:Z->6`。然后得到这4条边的所有输入符号组成的集合，也就是`{b,c,d}`。

第8行是计算从p出发输入符号为x的所有的边的输出符号(实际是`(p,z,v)`里的`z⋅y`)的最长公共子串，因为我们这里介绍的WFST的输入是一个符号(而不是一个字符串)，因此最长公共子串最长就是一个字符，如果相同输入的输出不同，那么最长公共子串就是ε。这一行代码也有点复杂，我们来仔细阅读它：
$$y' \leftarrow \land \{ z \cdot y | (p,z,v) \in p', (p,x,y,w,q) \in E \}$$

我们先看`(p,z,v)∈p′`，它先遍历`p’`的所有元素，根据p在原始WFST里找输入符号为x的所有边`(p,x,y,w,q)∈E`，然后把两个字符串z和y连接起来。其中z是`(p,z,v)`里余下的输出字符串，而y是边`(p,x,y,w,q)∈E`里的输出符号。这样对于每一条边`(p,x,y,w,q)∈E`，都可以计算一个`z⋅y`，最后符号`∧`表示求这些字符串的最长公共子串。这个计算结果是新的WFST里的边的输出符号。

读懂了第8行，第9行就非常类似了，只不过它是计算的是新的WFST里的边的weight。v是`(p,z,v)`里余下来的weight，而w是边`(p,x,y,w,q)∈E`里的weight，把它们用`⨂`乘起来，最后用`⨁`求和。

接下来第10行构造一个新的状态`q’`，这个状态也是一个集合，集合的每个元素依然是一个三元组(状态,余下的输出字符串,余下的weight)。其中状态是q。余下的输出字符串是`y′−1⋅z⋅y`，因为y′的字符串放到新的边里了，所以这条边余下的输出字符串是`z⋅y`乘以`y’`的逆，因此这里要求半环是weakly left-divisible的。余下的weight也类似，是`w′−1⨂v⨂w`，然后用`⨁`加起来。

这样就构造出`T’`的一条边：`(p’, x, y’,w’,q’)`，在第11行把它加到`E’`里。

如果新的状态`q’`之前没有出现过，那么需要把它加到`Q’`里。如果q’的某个状态是原始WFST的终止状态，则`q’`就是新的WFST的一个终止状态。它的终止weight `ρ(q′)`的计算是在第16行：`ρ(q′)={(z,⨁{v⨂ρ(q)|(q,z,v)∈q′,q∈F})}`，它是把剩余的输出字符串和weight都放到`ρ(q′)`里。

第18行把这个新的状态加入到待处理新状态集合S里，等待后续的处理。

下图是一个确定化的示例。图(a)是一个非确定的WFST T，而确定化算法生成的状态如图(b)所示。在这个例子里，`T’`的初始状态是`{(0,ϵ,0.2)}`，它的weight是$\bar{1}$(注：原文为0.2，我理解应该是$\bar{1}$)。从这个初始状态跳出的边是由原始WFST的两条边`0-a:X->1`和`0-a:Y->2`合并而成的，输出符号的公共前缀为`(ϵ⋅X)∧(ϵ⋅Y)=ϵ`。如果是热带半环，则新边的weight为$(\bar{1} \bigotimes 0.5) \bigoplus (\bar{1} \bigotimes 1.2)=0.5 \bigoplus 1.2=0.5$。而终点状态变成`{(1,X,0),(2,Y,0.7)}`，这个`0.7`是`0.5−1⨂1.2=0.7`。这里原始WFST的状态1和2被合并成新WFST里的一个状态。

<div align=center>
    <img src="zh-cn/img/ch17/p36.png"   /> 
</div> <p align=center>WFST确定化的例子</p>

接着，原始WFST里的状态4和6被输入符号”b”合并成新的状态`q′={(4,X,0),(6,Y,1.7)}`，因为状态4和6都是原始WFST的终止状态，所以这个新状态也是T’的终止状态，剩下的输出字符串和weight被放到`ρ(q′)={(X,0.3),(Y,1.7)}`里。图(b)中的其它状态也是通过类似的方法计算得到。最后我们把状态起一个新的名字(编号)，并且创建一个新的终止状态，让原来那些终止状态通过边”ε:余下的输出字符串/余下的weight”跳到这个新的终止状态。这样得到的WFST只有一个终止状态，如图(c)所示。


##### 2.5.2 Weight Pushing

Weight Pushing运算的作用是把一个WFST所有路径的weight分布往初始状态push，但是不改变任何成功路径的weight。在许多序列识别和转换问题里，寻找最可能或者最小代价是WFST需要解决的最重要的问题。当我们使用一个weighted的FA时，这个问题就变成FA搜索weight最大或者最小的成功路径的问题。Weight Pushing因为把路径的weight推到前面，因此对于那种look-ahead的算法(比如Beam搜索)，它能更快的滤掉早期不太有希望的路径，从而减少搜索时间。

<div align=center>
    <img src="zh-cn/img/ch17/p37.png"   /> 
</div> <p align=center>Weight Pushing的例子</p>

上图(a)是一个WFST，图(b)是在热带半环上的Weight Pushing的结果，图(c)是在log半环上的结果。在图(a)中，成功路径`0->1->3`的weight为`0⨂1⨂1⨂0.5=2.5`。在图(b)中，weight被尽量往前面push，成功路径`0->1->3`的weight变为`2.5⨂0⨂0⨂0`。而另一条成功路径`0->2->3`的weight从`0⨂0⨂3⨂0.5=3.5`变成了`2.5⨂1⨂0⨂0`。通过上面的分析，我们验证了Weight Pushing后的WFST确实没有改变成功路径的weight。

通用的Weight Pushing算法分为两步。第一步：计算每个状态的势(potential)，它是从这个状态到某个终止状态的所有路径的weight的和。第二步：把边的weight修改成起点和终点的势的差。这样就会让weight移到初始状态。注意每个跳转的weight是基于势的差，因此bias项会被消除掉并且移到初始状态。所有状态的势可以通过一个通用的从终止状态开始的最短路径算法得到，如下所示。

<div align=center>
    <img src="zh-cn/img/ch17/p38.png"   /> 
</div>


在这个算法了，在q的势V[q]的计算公式为：
$$V[q]=\underset{\pi \in \Pi(q,F)}{\bigoplus}w[\pi] \bigotimes \rho(n[\pi])$$

上式中$\Pi(q,F)$是从q出发到底终止状态的所有路径的集合。w[π]是路径π的weight的乘积。但是如果从q到某个终止状态的路径存在环(loop)的话，这个集合是无穷的。因为无法处理无穷的情况，这个算法假设半环是k-closed。因此，对于回路c，下面的等式：
$$\overset{l}{\underset{n=0}{\bigoplus}}w[c]^n=\overset{k}{\underset{n=0}{\bigoplus}}w[c]^n$$

在l>k时成立。因此如果一个回路的环(loop)重复k次以上，我们可以忽略k次以后的部分。

算法12的第1-7行是初始化状态q的势V[q]，对于终止状态，它的势为ρ(q)；而其它状态为$\bar{0}$。第8行把终止状态放到待处理队列S中，接下来的9-23行是一个大的循环，处理S中的所有状态直到它为空。

在第10-13行，状态q从S中弹出，r[q]暂存在R中，然后把r[q]设置为0¯。这里的r[q]代表从上次q被弹出之后累加的路径weight。

第14-22行，对于状态q的每一条入边e，路径的weight被传递到之前的状态p[e] (入边的起点)，这里$E^{-1}[q]$代表进入q的跳转(多重)集合。在第15行，p[e]的当前计算的势会和新的势——$V[p[e]] \bigoplus (R \bigotimes w[e])$进行比较。如果它们相同，则不做任何操作。否则需要更新p[e]的势并且把状态p[e]入队以便下一步累计路径的weight。$V[p[e]] \ne V[p[e]] \bigoplus (R \bigotimes w[e])$)是什么意思呢？我们假设这里是热带半环，则乘法⨁是min，因此$V[p[e]] \bigoplus (R \bigotimes w[e])$是找出(-log概率)最小的路径，其实也就是概率最大的路径。如果通过`q<-e-p[e]`有一条概率更大的路径，那么就应该更新p[e]的势。当S是空的时候，所有的势都不再发生变换，循环也就停止了。

上面的算法对于k-closed的半环肯定能循环终止。热带半环是0-closed。而log半环如果忽略很小的weight是k-closed。对于k-closed的半环，第15行判断`x=y`要改成”如果`|x−y|<δ`则认为`x=y`”。上面的算法队列可以是任何弹出的策略，实际通常使用优先队列，优先弹出势最大的状态，这样循环会更快的终止。

计算了状态的势之后，第二步就非常简单了，算法如下：

<div align=center>
    <img src="zh-cn/img/ch17/p39.png"   /> 
</div>

对于初始状态，它的weight ρ(q)要乘以V[q]。对于每一条边，它的weight要加上前后两个状态的差，也就是$V[q]^{-1} \bigotimes w[e] \bigotimes V[n[e]]$。最后对于终止状态，它的weight要”除以”(就是乘以逆)V[q]，也就是$V[q]^{-1}\rho(q)$。


##### 2.5.3 最小化(Minimization)

最小化是在所有与原始FA等价的DFA(不包括NFA)里寻找状态数最小的那个DFA。WFST的最小化算法包含两个步骤：

+ 把WFST的weight和输出标签往初始状态push
+ 使用经典的最小化算法，这里需要把`”输入:输出/weight”`看成一个标签

有很多最小化的算法。这些算法基本都是获取原来状态机状态集合的一个划分(partition)，所谓的划分(动词)是把一个集合切分成几个非空集合，这些集合的交集为空，并集为原始集合。每一个分块(partition)中的状态是等价的或者说不可区分的(not distinguished)，所谓不可区分指的是两个状态如该状态1有一条从它出发到某个终止状态的路径，它接受某个字符串，则状态2也一定存在到终止状态的路径也接受这个字符串；反之亦然。对于WFST来说，两个状态`q1,q2∈Q`是等价的充要条件是：
$$L(q_1,x)=L(q_2 , x), \forall x \in \Sigma^∗$$

其中，
$$L(q, x) = (o[\pi], w[\pi]) s.t. p[\pi] = q, i[\pi] = x, n[\pi] \in F$$

用自然语言来描述`L(q,x)`就是：存在一条路径`π`，它的起点是`q`，终点是终止状态，并且路径打输入字符串是x；则`L(q,x)`的值是这条路径的输出字符串和weight。如果从q出发输入字符串x无法走到终止状态呢？那就没有定义(意义)。因此充要条件的含义是：对于任何一个字符串x，如果能从q1走到终止状态，则x也能使得$q_2$走到终止状态，而且这两条路径的输出字符串和weight也要完全相同。这里我们假设WFST是确定的，因此路径是唯一的。

得到状态集合的划分之后，同一个划分的所有状态被替换成一个新的状态。原来状态的所有跳转都要迁移到这个新的状态里，同一个输入符号的多个跳转需要合并。

下图(a)是对原始WFST T(原始的T在上图(c))进行push(det(T))之后的结果，首先进行确定化，然后进行weight pushing。我们发现状态3和4是等价的，因此最小化后它们被合并成一个状态。注意，在weight pushing之前，状态3和4并不是等价的，所以则最小化前需要先做weight pushing。label pushing也可能是需要的。比如我们可以把输出符号也看成一个字符串半环上的weight，然后进行weight pushing(把公共的前缀往前push)。

<div align=center>
    <img src="zh-cn/img/ch17/p40.png"   /> 
</div> <p align=center>最小化的例子</p>

Hopcroft算法是非常流行的最小化DFA的有效算法，它的计算复杂度是$O(\vert E \vert log \vert Q \vert)$。这个算法会遍历目前的每一个块(block，一开始只有一个块)，然后不断的切分(split)这些块直到它里面的状态都是等价的。为了切分当前划分的每一个块，首先会选择一个块为splitter，然后其他块被切分。在切分的每一步里，如果一个块的部分状态组成的集合会被移出这个块——条件是这些状态在给定输入符号时会跳到splitter的某个状态里。然后原来的块会被切分成两个：被移出的状态集合以及剩下的状态集合。通过上面的步骤，每个块被逐渐提炼(refine)成等价状态的集合。这里不做证明，很多文献都有详细的介绍。下面是针对WFST做了微小修改的Hopcroft最小化算法。

<div align=center>
    <img src="zh-cn/img/ch17/p41.png"   /> 
</div> 

在第1行，当前划分P和队列W初始化为空集∅。队列W是一个等待列表，它包含用于切分P中块的切分块(splitter)。第2-7行进行初始划分，所有的非终止状态是一个集合，而终止状态根据其weight是否相同划分成不同的集合。在第5行，终止状态组成的块会放到W里作为splitter。

原始的Hopcroft算法把状态集合划分成两个块F和Q-F。对于WFST，我们进一步把F根据终止weight划分成不同的集合，因为相同的weight的终止状态才是等价的。此外，我们还可以利用每个状态的跳出边的信息来进一步细粒度的初始划分，因为如果两个状态的出边的输入符号、输出符号和wegiht有任何一个不同，则这两个状态就是可以区分的(不等价)。这样初始化的话我们可以把状态切分到更多更细粒度的块。这样的初始化可以加速算法。不过这里由于篇幅的限制我们不详细介绍。

第8-27行迭代的切分块。第9行，从队列W里弹出一个切分块(splitter)S。第10行遍历跳进S的所有三元组(i/输入符号，o/输出符号，w/weight)，这里$E^{-1}[S]$表示这样的边——这条边的终点包含在S里，用数学语言来描述就是$\{e \in E \vert n[e] \in S \}$。我们把跳入S并且三元组是(i,o,w)的边的起点(状态)组成的集合记作$R_{i,o,w}$。根据三元组(i,o,w)，如果一个块B的边包含$E^{-1}[S]$里的一条边(也就是块B可以跳到S)并且$B \not\subseteq R_{i,o,w}$(也就是至少还有一条状态不是跳到S的)，则我们可以把B切分成两个子集：$B_1=B \cap R_{i,o,w}$(跳到S的状态集合)和$B-B_1$(不跳到S的状态集合)。如果B属于splitter集合W，第15行把B从划分中去掉，替换成两个子集B1和B2。然后把B1和B2加到W里作为splitter。否在如果B不属于W，则把B1和B2中元素个数较少的放到W里。

等价状态的集合划分完成后，第28-35行利用划分来重新构建一个最小化的WFST。第28行用划分P得到新的状态集合$Q′$。第29-31行，对于原始WFST的每一个条边`e∈E`，找到边e的起点(`p[e]`)对应的划分，作为新边的起点，类似的方法出来终点。这里B(s)表示得到状态s所在的划分(的ID)。新边的输入符号、输出符号和weight保持不变。

第32-35行处理新状态的终止状态和weight：如果某个划分里的所有状态都是原始WFST的终止状态，则这个划分S构成的新状态就是新WFST里的一个终止状态，并且它的weight是S里某个状态的weight(所有状态的weight应该是相同的，否则就不等价里)，也就是$\rho’(S)=\rho(p), p \in S$。

因为Hopcroft算法是通用的算法，所以它也可以用于任何确定的WFST，这也包括有环的确定的WFST。如果WFST是无环的，则可以使用更加高效的Revuz算法，其计算复杂度是$O(\vert E \vert)$。在这个算法里，初始划分是通过从终止状态开始用深度优先搜索得到的一个最大高度(height)的划分。每个块根据输入符号基于最大的高度来进行切分。详细介绍可以参考[Minimisation of acyclic deterministic automata in linear time](https://core.ac.uk/download/pdf/82324227.pdf)。


##### 2.5.4 消除ε跳转

ε消除算法是把一个ε-NFA转换成等价的没有ε的NFA。前面提到过，ε的存在使得FA不确定。虽然前面介绍的FA的确定化算法可以应用与ε-NFA——我们需要把ε看成一个普通的输入符号，但是这样得到的FA还是包含ε的。因此最终的FA看起来像DFA，但是实际还是个NFA。如果我们在确定化算法使用之前先消除ε，则这个FA就可以完全的(真正的)被确定化。

ε消除算法的基本思路是删除ε-跳转，然后把它替换成新的非ε-跳转，这些新跳转是原来的跳转里的一个或者多个ε-跳转加上一个非ε-跳转得到。新跳转的输入符号还原来的非ε-跳转的一样。如果有一个非终止状态能通过ε-跳转到某个终止状态，则在消除里ε跳转的FA里这个非终止状态也变成终止状态。下图展示里ε消除的基本概念。

<div align=center>
    <img src="zh-cn/img/ch17/p42.png"   /> 
</div> <p align=center>ε消除的基本概念</p>

图(a)是一个ε-NFA的一部分。ε消除算法首先找到每个状态的ε闭包(closure)。一个状态的ε闭包是这个状态可以通过一个或者多个ε-跳转到达的所有状态组成的集合。图(b)中的灰色背景的状态1和2说明它们属于状态0的ε闭包。同时则图(b)中ε闭包里的状态1和2出去的非ε跳转”2-a->4”、”2-b->5”和”1-c->3”会产生新的”0-a->4”、”0-b->5”和”0-c->3”。最后ε闭包只保留一个状态0，其余的状态2和3以及它们的边都删除掉，就打得到图(c)里的没有ε的NFA。

前面介绍的是NFA(接收机)的ε消除算法，但是WFST还有输出符号和weight，因此还需要进行扩展。这里介绍Generic ε-Removal and Input ε-Normalization Algorithms for Weighted Transducers里的算法。首先，这个算法把输入和输出符号都是ε的边ε:ε当成一个ε来处理。其次，给定一个状态，需要计算这个状态和它的ε闭包里的每一个状态的距离，并且乘以最后一个非ε跳转的weight来得到新跳转的weight。闭包里两个状态的路径可以使用标准的单元最大路径算法来实现(只走ε的边)。下面是WFST的ε消除算法代码。

<div align=center>
    <img src="zh-cn/img/ch17/p43.png"   /> 
</div> 

这个算法遍历WFST状态集合Q里的每一个状态p，`ε:ε`这样的跳转会被丢弃然后替换成和原来等价的非ε跳转。在第2行，非ε的跳转直接保留下来复制到E′。在第3行，对于状态p的ε闭包里的每一个`(q, w’)`(`w’`是p通过ε跳转到q的距离)，q出发的某个非ε跳转`(q,x,y,w,r)`会被替换成从p出发的新跳转，这个新跳转的输入和输出符号不变，weight是`w′⨂w`，这里要求`(x,y)`不等于`(ε,ε)`。第5-14行检查p是否能够通过ε跳转到达终止状态，如果是的话，需要把p也加到终止状态集合里，并且计算相应的`ρ′`。具体来说，如果p属于终止状态，那么`ρ′(p)=ρ(p)`；如果p通过ε跳转到达终止状态q，则`ρ′(p)←ρ′(p)⨁(w′⨂ρ(q))`。

注意：上面的算法只消除`ε:ε`这样的边，而`ε:x`或者`x:ε`仍然会保留下来。为了尽可能多的消除ε，我们可以在使用上面的算法前先进行同步(synchronization)。同步算法会把一个WFST转换成等价的并且对于成功的路径他会尽量同步的消费输入和输出符号的WFST。因此同步后的WFST会增加`(x:x)`和`(ε:ε)`这样的边而减少`(x:ε)`和`(ε:x)`这样的边。同步之后，ε消除算法能够更多的消除ε跳转。关于同步算法，感兴趣的读者可以参考Mehryar Mohri的[Weighted automata algorithms](https://link.springer.com/chapter/10.1007/978-3-642-01492-5_6)。
