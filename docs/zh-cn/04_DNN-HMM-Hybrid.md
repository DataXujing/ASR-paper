## DNN-HMM Hybrid

<!-- 参考 语音识别实战一书的第六章 -->

**1.模型结构**

DNN不能直接为语音信号建模，因为语音信号是时序连续信号，而DNN需要固定大小的输入。为了在语音识别中利用DNN的强分类能力，我们需要找到一种方法来处理语音 信号长度的变化问题。

在ASR中结合DNN和HMM的方法始于20世纪80年代末和20世纪90年代初。那时提出了各种各样不同的结构及训练方法(参见文献`[1]`).最近随着DNN很强的表现学习能力被广泛熟知，这类研究正在慢慢复苏。

其中一种方法的有效性已经被广泛证实。他就是如图1所示的DNN-HMM混合系统。在这个框架中，HMM用来描述语音信号的动态变化，而观察特征的概率则通过DNN来估计。在给定声学观察特征的条件下，我们用DNN的每个输出结点来估计连续密度HMM的某个状态的后验概率。除了DNN内在的鉴别性属性，DNN-HMM还有两个额外的好处:训练过程可以使用维特比算法，解码通常也非常高效。

<div align=center>
    <img src="zh-cn/img/ch4/p1.png" /> 
</div>

<p align=center>图1:混合系统的结构。HMM对语音信号的序列特性进行建模，DNN对所有聚类后的状态（聚类后的三音素状态）的似然度进行建模[2-1]。这里对时间上的不同点采用同样的DNN</p>

在20世纪90年代中叶，这种混合模型就已经被提出，在大词汇连续语音识别系统中，他被认为是一种非常有前景的技术。在文献`[2,3,4]`中，他被称为DNN-HMM混合模型。在早期基于混合模型的方法中，**通常使用上下文无关的音素状态作为DNN训练的标注信息**，并且只用于小词汇任务。DNN-HMM随后被扩展到上下文相关的音素建模`[6]`,以及用于中型和大词表的自动语音识别任务`[5]`.DNN-HMM的应用中也包含循环神经网络的结构。

然而，在早期基于上下文相关的DNN-HMM混合结构`[7]`研究中，对上下文相关音素的后验概率建模为：
$$p(s_i,c_j|x_t)=p(s_i|x_t)p(c_i|s_j,x_t)$$

或者

$$p(s_i,c_j|x_t)=p(c_i|x_t)p(s_i|c_j,x_t)$$

其中，$x_t$是在时刻$t$的声学观察值，$c_j$是聚类后的上下文种类$\{c_1,...,c_J\}$中的一种，$s_i$是一个上下文无关的音素或者音素中的状态。DNN用来估计$p(s_i|x_t)$和$p(c_i|s_j,x_t)$.**尽管这些上下文相关的DNN-HMM模型在一些任务中性能优于GMM-HMM，但其改善并不大。**

这些早期的混合模型有一些重要的局限性。例如，由于计算能力的限制，人们很少使用拥有两层隐层以上的DNN模型，而上述的上下文相关模型不能够利用很多在GMM-HMM框架下很有效的技术。

最近的技术发展`[7-13]`则说明，如下几个改变可以使我们获得重大的识别性能提升：首先，我们把传统的浅层网络替换成深层（可选择的预训练）神经网络。其次，使用聚类后的状态（绑定后的三音素状态）代替单音素的状态作为神经网络的输出单元。这种改善后的DNN-HMM混合模型称为CD-DNN-HMM`[8]`直接为聚类后的状态建模同时也带来其他两个好处：首先，在实现一个CD-DNN-HMM系统的时候，对已存在的CD-DNN-HMM系统修改最小。其次，既然DNN输出单元可以直接反应性能的改善，任何在CD-DNN-HMM系统中模型单元的改善（例如：跨词三音素模型）同样可以适用于CD-DNN-HMM系统。

在CD-DNN-HMM中，对于所有的状态$s\in [1,S]$，我们只训练一个完整的DNN来估计状态的后验概率$p(q_t=s|x_t)$。这和传统的GMM不同，因为GMM框架下，我们会使用其多个不同的GMM对不同的状态建模。除此之外，典型的DNN输入不是单一的一帧，而是一个$2w+1$（如9-13）帧大小的窗口特征$x_t=[o_{max(0,t-w)}...o_t...o_{min(T,t+w)}]$,这使得相邻帧的信息可以被有效的利用。

**2.用CD-DNN-HMM解码**

在解码过程中，既然HMM需要似然度$p(x_t|q_t)$，而不是后验概率，我们就需要把后验概率转为似然度：
$$p(x_t|q_t=s)=p(q_t=s|x_t)p(x_t)/p(s)$$

其中$p(s)=\frac{T_s}{T}$是从训练集中统计的每个状态（聚类后的状态）的先验概率，$T_s$是标记属于状态$s$的帧数，$T$是总帧数。$p(x_t)$是与字词序列无关的，计算时可以忽略，这样就得到经过缩放的似然度：
$$\bar{p}(x_t|q_t)=p(q_t=s|x_t)/p(s)$$

尽管在一些条件下除以先验概率$p(s)$可能不能改善识别率。但是他在缓解标注不平衡问题中是非常重要的，特别是训练语句中包含很长的静音片段时就更是如此。

总之，在CD-DNN-HMM解码出的字词序列$\hat{w}$是由以下公式确定的
$$\hat{w}=arg max_{w}p(w|x)=arg max_{w}p(x|w)p(w)/p(x)=argmax_{w}p(x|w)p(w)$$

其中$p(w)$是*语言模型*，以及：

$$p(x|w)=\sum_{q}p(x,q|w)p(q|w) \approx max\pi(q_0)\prod^{T}_ {t=1}a_{q_{t-1}q_t}\prod^{t}_{t=0}p(q_t|x_t)/p(q_t)$$

是*声学模型*，其中$p(q_t|x_t)$由DNN计算得到，$p(q_t)$是状态的先验概率，$\pi(q_0)$和$a_{q_{t-1}q_t}$分别是初始状态概率和状态转移概率，由HMM决定。和GMM-HMM类似，语言模型权重系数$\lambda$通常被用于平衡声学模型和语言模型得分，最终解码路径由以下公式确定(取log)
$$\hat{w}=argmax_w[logp(x|w)+\lambda logp(w)]$$

**3.CD-DNN-HMM训练过程**

可以使用嵌入的维特比算法来训练CD-DNN-HMM，主要步骤参考算法1。CD-DNN-HMM包含三个组成部分，一个深度神经网络DNN,一个隐马尔可夫模型HMM,以及一个状态先验概率分布prior.由于CD-DNN-HMM的第一步就是使用训练数据训练一个GMM-HMM系统。因为DNN训练的标注是由GMM-HMM系统采用维特比算法产生得到的，而且标注的质量会影响DNN系统的性能。因此，训练一个好的GMM-HMM系统作为初始模型就非常重要。

一旦训练好GMM-HMM模型hmm0，我们就可以创建一个从状态名字到senoneID（每个物理三音素拥有若干个（例如3个）绑定状态（用senones表示））的映射。这个从状态到senoneID的映射(stateTosenoneIDMap)的建立并不简单。这是因为每个逻辑三音素HMM是由经过聚类后的一系列物理三音素HMM代表的。换句话说，若干个逻辑三音素可能映射到相同的物理三音素。

<div align=center>
    <img src="zh-cn/img/ch4/p2.jpg" width=80% /> 
</div>

<p align=center>算法1：训练CD-DNN-HMM的主要步骤</p>

使用已经训练好的GMM-HMM模型hmm0,我们可以在训练数据上采用维特比算法生成一个状态层面上的强制对齐，利用stateTosenoneIDMap，我们能够把其中的状态名转为senoneIDs。然后可以生成从特征到senoneID的映射对(featuresenoneIDPairs)来训练DNN.相同的featuresenoneIDPairs也被用来估计senone先验概率。

利用GMM-HMM模型hmm0,我们也可以生成一个新的隐马尔可夫模型hmm,其中包含和hmm0相同的状态转移概率，以便在DNN-HMM系统中使用。一个简单的方法是把hmm0中的每个GMM(即每个senoneID模型)用一个（假的）一维单高斯模型代替。搞死模型的方差（或者说是精度）是无所谓的，他可以设置成任意的正整数（例如总设置成1）均值被设置为其对应的senoneID。应用这个技巧之后，计算每个senone的后验概率就等价于从DNN的输出向量中查表，找到索引是senoneID的输出对数概率。

在这个过程中，我们假定一个CD-DNN-HMM存在，并被用于生成senone对齐。在这种情况下，用于对三音素状态聚类的决策树也是在GMM-HMM训练的过程中构建的。但这其实不是必须的，如果我们想完全去除图中的GMM-HMM步骤，可以通过均匀的把每个句子分段(称为flat-start)来构建一个单高斯模型，并使用这个信息作为训练标注。这可以形成一个单因素DNN-HMM，我们可以用它重新对句子进行对齐。然后可以对单个音素估计一个单高斯模型，并采用传统方法构建决策树。事实上，这种无需GMM的CD-DNN-HMM是能够成功训练的，这一成果发表在`[14]`.

对含有$T$帧的句子，嵌入的维特比训练算法最小化交叉熵的平均值，其等价于负对数似然
$$J_{NLL}(W,b;x,q)=-\sum^{T}_{t=1}logp(q_t|x_t;W,b)$$

如果新模型$(W^{'},b^{'})$相比于旧模型$(W,b)$在训练准则上有改进，我们有
$$-\sum^{T}_ {t=1} log p(q_t|x_t;W^{'},b^{'}) < - \sum ^{T}_ {t=1} log p(q_t|x_t;W,b) $$

对于每个对齐后的句子的分数为

<div align=center>
    <img src="zh-cn/img/ch4/p3.jpg"  /> 
</div>

换句话说，新的模型不仅能提高帧级别交叉熵，而且能够提高给定字词序列的句子似然分数。这里证明了嵌入式的维特比算法的正确性。`[15]`中给出了另一个不同的嵌入式维特比训练算法有效性的证明。值得一提的是，在这个训练过程中，尽管所有的竞争词的分数和总体上是下降的，但并不保证每个竞争词的分数都会下降。而且，上述说法（提高句子似然度）一般说虽然是正确的，但并不保证对每个单独的句子都正确。如果平均的交叉熵改善很小，尤其是当这个很小的改善来自对静音片段更好的建模时，识别的准确度可能会降低。一个原理上更合理的CD-DNN-HMM方法是使用“序列鉴别性训练准则”(这里将不讨论这个方法)


**4.上下文窗口的影响**

使用一个窗（典型的是9到13）包含的全部帧特征作为CD-DNN-HMM的输入可以实现优异的性能。显然，使用一个长的窗口帧，DNN模型可以利用相邻帧信息。引入相邻帧，DNN也可以对不同特征帧之间的相互关系进行建模，这样部分缓和了传统的HMM无法满足观察独立性假设的问题。

每个字词序列的分数通过以下公式得到

$$logp(x|w)=log\pi(q_0)+\sum^{T}_ {t=1} log(a_{q_{t-1}q_t})+\sum^{N}_ {n=1}[logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)]$$

其中，$T$是特征的长度，$ N<T $是状态序列的长度，$s_n$是状态序列中第$n$个状态，$q_t$是在$t$时刻的状态，$t_n$是第$n$个状态的起始时间。这里假设状态的时长可以用一个马尔可夫链来模拟。注意，观察值分数$logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)$表示在给定状态$s_n$的情况下，观察到的特征段的对数似然概率，他可被用于基于分段的模型`[15]`,在HMM中，每个特征帧都假设与其他特征帧条件独立，因此

$$ logp(o_{t_n},...,o_{t_{n+1}-1}|s_n) \simeq \sum^{t_{n+1}-1}_{t=t_n}[logp(o_t|s_n)] $$

我们知道这个假设在真实世界中是不成立的，对给定相同的状态，既然相邻的帧是互相关的，为了对帧之间的相关性建模，段的分数应该估计为
$$ logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)=\sum^{t_{n+1}-1}_{t=t_n}logp(o_t|s_n,o_{t_n},...,o_{t-1}) $$

我们知道，如果两帧相隔太远（例如超过M帧）。他们可以被认为是不相关。在这个条件下，以上分数能够近似的表示为：

<div align=center>
    <img src="zh-cn/img/ch4/p4.jpg"  /> 
</div>

其中，$c$是一个与$s_n$不相关的常量，$x^{M}_ t=\{o_{t-M},...,o_{t-1},o_t\}$是M帧拼接而成的特征向量。我们假设状态先验概率和观察值不相关。可以看到DNN模型中引入邻接帧（例如：估计$p(s_n|x^M_{t})$)我们可以更加准确的估计分段函数，同时还可以有效的利用HMM中独立性的假设。



**5.CD-DNN-HMM的消融实验**

在许多大词汇连续语音识别任务中，CD-DNN-HMM比GMM-HMM表现更好，因此，了解哪些模块或者过程对此做了贡献是很重要的。本节将会讨论哪些决策会影响识别准确性。特别的，我们会在实验上比较以下几种决策的表现差别：

+ 单音素对齐和三音素对齐
+ 单音素状态集和三音素状态集
+ 使用浅层和深层神经网络
+ 调整HMM的转移概率或者不调

一系列研究的实验结果`[7,8,12,16,13]`表明，带来性能提升的三个关键因素是：

+ 使用足够深的深度神经网络
+ 使用一长段的帧作为输入
+ 直接对三音素进行建模
  
在所有的试验中，来自CD-DNN-HMM的多层感知器模型(DNN)的后验概率代替GMM,但其他保持不变。


5.1 进行比较和分析的数据集和实验

+ 必应（bing）移动语音搜索数据集

必应移动语音搜索（VS）应用让用户在自己的移动手机上做全美国的商业和网页搜索。用在实验中的这个商业搜索数据集采集于2008年的真实应用场景，当时这个应用被限制在位置和业务查询`[16]`.所有的音频文件的采样率为8kHz，并用GSM编码器编码。这个数据集具有挑战性，因为它包含多种变化：噪声，音乐，旁人说话，口音，错误的发音，犹豫，重复，打断和不同的音频信道。

数据集被划分为训练集，开发集和测试集。数据集根据查询的时间戳进行分割，这是为了模拟真实数据采集和训练过程，并避免三个集合之间的重叠。训练集的所有查询比开发集的查询早，后者比测试集的查询早。我们使用卡内基-梅隆大学的公开词典。在测试集中使用了一个包含了65K个一元词组，320万个二元词组和150万个三元词组的归一化的全国范围的语言模型，是用数据和查询日志训练的，混淆度为117。


<div align=center>
    <img src="zh-cn/img/ch4/p5.png"  /> 
</div>
<p align="center">必应移动搜索数据集 </p>

我们使用句子错误率（SER）,而不是词错误率（WER）来衡量系统在这个任务上的表现。平均句子长度为2.1个词，因此句子一般来说比较短。另外，用户最关心的是他们能否用最少的尝试次数来找到事物或地点。他们一般会重复识别错误的词。另外，在拼写中有巨大的不一致，因此用句子错误率更加方便。在使用这个65K大词表的语言模型中，开发集和测试集在句子层面上的未登录词（Out-of-vocabulary words)比率都为6%，也就是说在这种配置下最好的可能的句子错误率就是6%。

GMM-HMM采用了状态聚类后的跨词三音素模型。训练采用的准则是最大似然（ML),最大互信息（MMI)和最小音素错误（MPE)准则。试验中采用39维的音频特征，其中13维是静态的梅尔倒谱系数（MFCC)(C0被能量替代)，以及其一阶和二阶导数（差分）这些特征采用频谱均值归一化算法进行预处理。

基线系统在开发集上调试了如下参数，状态聚类的结构，三音素数量，以及高斯分裂的策略。最后所有的系统有35K个逻辑三音素和2K个物理三音素，761个共享的状态（三音素），每个状态是24个高斯GMM模型，GMM-HMM基线的结果在下表。

<div align=center>
    <img src="zh-cn/img/ch4/p6.png"  /> 
</div>
<p align="center">CD-GMM-HMM系统在必应数据集上的SER </p>

对VS数据集上的所有CD-DNN-HMM实验，DNN的输入特征是11帧的MFCC特征。在DNN预训练时，所有的层对每个采样都采用了$1.5e^{-4}$的学习率。在训练中，在前六次迭代中，学习率为$3e^{-3}$每帧，在最后6次迭代中是$8e^{-5}$。在所有的试验中，mini-batch的大小为256，惯性系数为0.9.这些参数都是手动设定的，他们基于单隐层神经网络的前期实验，如果尝试更多超参数的设置，可能得到的效果会更好。

+ Switchboard数据集

Switchboard(SWB)数据集`[19,20]`是一个交谈式电话语音数据集。他有三个配置，训练集分别为30个小时（SWB-I训练集的一个随机子集)，309个小时（SWB-I全部训练集）和2000个小时（加上Fisher训练集）。在所有的配置下，NIST2000Hub5测试集1831段的SWB部分和NIST2003春季丰富语音标注集（RT03S,6.3小时）的FSH部分被用作了测试集。系统使用了13维的PLP特征（包括三阶差分），做了滑动窗口的均值-方差归一化，然后使用异方差线性判别式（HLDA）`[21]`降维到39维。在30小时，309小时，2000小时三个配置下，说话人无关的跨词三音素模型使用了1504（40高斯），9304（40高斯）和18804(72高斯)的共享状态（GMM-HMM系统）。三元词组语言模型使用2000个小时的Fisher标注数据训练，然后与一个基于书面语文本数据的三元组语言模型进行插值。当使用85K词典时，测试集的混淆度为84.

DNN系统使用SGD训练，除了第一次迭代的batch为256帧，其余batch设为1204帧。在深度置信网络预训练的时候mini-batch为256.

对于预训练，每个样本的学习率为$1.5e^{-4}$.对于前24个小时的训练数据，每帧的学习率为$3e^{-3}$，三次迭代后改为$8e^{-5}$,惯性系数为0.9。这些参数设置跟语音搜索数据集(VS)相同。

5.2 对单音素或者三音素的状态进行建模

在下表中展示了对三音素，而不是单音素进行建模的优势，在VS数据集上有15%的句子错误率的相对降低(使用了一个3隐层的DNN,每层2K个神经元)，而第二个表展示了309小时的SWB数据集中得到的50%的相对词错率的降低，这里使用了一个7层的DNN，每层2K个神经元。这些相对提升的不同部分是由于在SWB中更多的三音素被使用了。在分析中发现，使用三音素是我们得到性能提升的最大单一来源。


<div align=center>
    <img src="zh-cn/img/ch4/p7.png"  /> 
</div>
<p align="center">VS数据上的句错率(SER) </p>

<div align=center>
    <img src="zh-cn/img/ch4/p8.png"  /> 
</div>
<p align="center">SWB数据上的词错率(WER) </p>


5.3 越深越好

在CD-DNN-HMM中，另一个关键部分是使用DNN而不是浅的MLP.下表展示了当CD-DNN-HMM中的层数变多时，句子错误率的下降。如果只使用1个隐藏层，句错率是31.9%，当使用了3层隐藏层时，错误率降低到30.4%，4层的错误率降低到29.8%，5层的错误率降低到29.7%。总的来说相较于单层模型，5层网络模型带来了2.2%的句错率的降低。

为了展示深度神经网络带来的效益，单隐层16K个神经元的结果也展示在了下表。因为输出层有761个神经元，这个浅层的模型比5层2K个神经元的模型需要更多的空间。这个很宽的浅模型的开发集的句错率为31.4%，比单层的2K神经元的31.9%稍好，但比深层模型要差。

<div align=center>
    <img src="zh-cn/img/ch4/p9.png"  /> 
</div>
<p align="center">VS数据不同隐层的DNN的SER </p>

下表展示了使用309小时的SWB数据的测试集上的WER结果。下表展示，深层的模型比浅层的模型有更强的区分能力。在加大深度时，词错率保持了持续的降低。更加有趣的是，如果比较5x2k和1x3772的配置，或者比较7x2k和1x4634的配置（他们有相同的餐数量），那么深层模型比浅层模型表现更好。即使我们把单隐层MLP的神经元增加大16k,也只能到22.1%的WER,比相同条件下7x2k的DNN得到的17.1%要差的多。如果我们继续加大层数，那么性能提升会更少，到9层时饱和。在实际中我们需要在词错率提升和训练解码代价提升之间做出权衡。

<div align=center>
    <img src="zh-cn/img/ch4/p10.png"  /> 
</div>
<p align="center">SWB数据不同隐层的DNN的WER </p>


5.4 利用相邻的语音帧

下表对比了309小时SWB任务中使用和不使用相邻语音帧的结果。可以很明显的看出，无论使用的是浅层还是深层网络，使用相邻帧的信息都能显著提高准确率。不过，深度神经网络获得更高的提升，他有24%的相对词错率的提升，而浅层模型只有14%的相对词错率的提升，他们都有相同数量的参数。另外我们发现，如果只使用単帧，DNN系统比BMMI[21]训练的GMM系统好了一点点（23.2%比23.6%）。但是注意，DNN系统的表现可以通过类似BMMI的序列鉴别性训练[22]来进一步提升。为了在GMM系统中使用相邻的帧，需要使用复杂的技术，如fMPE[23],HLDA[24],基于区域的转换[25]或者tandem[26,27]。这是因为要在GMM中使用对角的协方差矩阵，特征各个维度之间需要是统计不相关的。DNN则是一个鉴别性模型，无论相关还是不相关的特征都可以接受。

<div align=center>
    <img src="zh-cn/img/ch4/p11.png"  /> 
</div>
<p align="center">SWB数据使用相邻帧的比较 </p>


5.5 预训练

2011年之前，人们相信预训练对训练深度神经网络来说是必要的。之后研究者发现预训练虽然有时能带来更多的提升，但不是关键的，这可以从下表中看到。下表说明不依赖标注的深度信念网络(DBN)预训练，当隐层数小于5时，确实比没有任何预训练模型来说提升显著。但是当隐层数量增加时，提升变小了，并且最终消失。这和使用预训练的初衷是违背的。研究者曾经猜想，当隐层数量增加时，我们应该看到更多的提升，而不是更少。这个表现可以部分说明，随机梯度下降有能力跳出局部最小值。另外当大量数据被使用时，预训练所规避的过拟合问题也不再是一个严重的问题。

<div align=center>
    <img src="zh-cn/img/ch4/p12.png"  /> 
</div>
<p align="center">不同预训练的性能对比。SWB数据测试词错率，NOPT:没有预训练，DBN-PT:深度信念网络预训练，DPT:鉴别性预训练 </p>

另一方面，当层数变多时，生成性预训练的好处也会降低。这是因为深度信念网络训练使用了两个近似。第一，在训练下一层时，使用了平均场逼近方法。第二，采用对比发散算法来训练模型参数。这两个近似对每个新增的层都会引入误差。随着层数变多，误差也累积变大，那么深度信念网络的预训练的有效性就降低了。鉴别性预训练(DPT)是另一种预训练技术。上表表现出了与深度信念网络一样的效果，特别是DNN有5个隐层以上时。不过，即使使用DPT,对纯BP的性能提升依然不大。虽然WER的降低比人们期望的要小，但预训练依然能确保训练的稳定性。使用这些技术后，我们能避免不好的初始化并进行隐式的正规化，这样即使训练集很小，也能取得好的性能。


5.6 训练数据的标注质量影响

在嵌入式维特比训练过程中，强制对齐被用来生成训练的标注。从直觉上说，如果用一个更加准确的模型来产生标注，那么训练的DNN会更好。下表证实了这一点。我们可以看到，使用MPE训练的CD-DNN-HMM生成的标注，在开发集和测试集上的句错率是29.3%和31.2%。他们比使用ML训练的CD-GMM-HMM的标注好了0.4%。因为CD-DNN-HMM比CD-GMM-HMM表现的更好，我们可以使用CD-DNN-HMM产生的标注来加强性能。下表展示了CD-DNN-HMM的标注的结果，在开发集和测试集上的句错率分别降低到28.3%和30.4%。


<div align=center>
    <img src="zh-cn/img/ch4/p13.png"  /> 
</div>
<p align="center">VS数据集标注质量和转移概率调整对比 </p>


SWB上也能得到类似的观察。当7x2k的DNN使用训练CD-GMM-HMM系统的标注训练，词错率是17.1%，如果使用CD-DNN-HMM产生标注，词错率是16.4%。



5.7 调整转移概率

上表表明，在CD-DNN-HMM中调整转移概率起到的效果并不明显。但是调整转移概率伴随着另一个优点，当直接使用CD-DNN-HMM中取出转移概率时，通常是在声学模型权重取2的时候得到最好的解码结果。然而，在调整转移概率之后，在语音检索任务中，不必再调整模型的权重。


**6.基于KL距离的HMM（不做重点讨论）**

在DNN-HMM的混合系统中，观测概率是满足限制条件的真实概率。然而，我们可以移除这些限制条件，并且将状态的对数似然度替换成其他成分。在基于KL距离的HMM(KL-HMM)[29,30]中，状态得分通过以下公式计算

$$ S_{KL}=KL(y_s||z_t)=\sum_{d=1}^{D}y_s^dln\frac{y_s^d}{z_t^d}$$

这里$s$表示一个状态，$z_t^d=p(a_d|x_t)$是观测样本$x_t$属于类别$a_d$的后验概率（DNN的输出），$D$表示类别的数目，$y_s$表示状态$s$的概率分布。理论上，$a_d$可以是任意类别。但实际上，$a_d$一般选择上下文无关的音素或者状态。例如$z_t$可以是一个用来输出神经元表示单因素的DNN输出。

与混合DNN-HMM系统不同，在KL-HMM中，$y_s$是一个需要对每个状态进行估计的额外模型参数，在[29,30]中，$y_s$是固定$z_t$（固定DNN)的情形下，通过最小化上式中定义的平均每帧得分来得到最优化的。

除此之外，反向KL(RKL)距离

$$ S_{RKL}(s,z_t)=KL(z_t||y_s)=\sum_{d=1}^{D}z_t^dln\frac{z_t^d}{y_s^d}$$

或者对称KL(SKL)距离
$$ S_{KL}(s,z_t)=KL(y_s||z_t)+KL(z_t||y_s)$$

也可以被用作状态得分。

我们需要注意的是，KL-HMM可以被视为一种特殊的DNN-HMM，他采用了$a_d$作为一个DNN中D维瓶颈层中的隐层神经元，并把DNN的softmax层替换为KL距离，因此，为了公平比较，当比较DNN-HMM和KL-HMM时，DNN-HMM需要增加额外一层。

除了比DNN-HMM更复杂外，KL-HMM还有另外两个缺点：

1.KL-HMM的模型参数是在DNN模型之外独立估计的，而不是像DNN-HMM一样所有的参数都是联合优化的；

2.KL-HMM采用序列鉴别性训练并不如DNN-HMM那样直观。因此虽然KL-HMM是一个有意思的模型，但是在此不做过多讨论。