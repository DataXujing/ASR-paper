## DNN-HMM Hybrid

<!-- 参考 语音识别实战一书的第六章 -->

**1.模型结构**

DNN不能直接为语音信号建模，因为语音信号是时序连续信号，而DNN需要固定大小的输入。为了在语音识别中利用DNN的强分类能力，我们需要找到一种方法来处理语音 信号长度的变化问题。

在ASR中结合DNN和HMM的方法始于20世纪80年代末和20世纪90年代初。那时提出了各种各样不同的结构及训练方法(参见文献`[1]`).最近随着DNN很强的表现学习能力被广泛熟知，这类研究正在慢慢复苏。

其中一种方法的有效性已经被广泛证实。他就是如图1所示的DNN-HMM混合系统。在这个框架中，HMM用来描述语音信号的动态变化，而观察特征的概率则通过DNN来估计。在给定声学观察特征的条件下，我们用DNN的每个输出结点来估计连续密度HMM的某个状态的后验概率。除了DNN内在的鉴别性属性，DNN-HMM还有两个额外的好处:训练过程可以使用维特比算法，解码通常也非常高效。

<div align=center>
    <img src="zh-cn/img/ch4/p1.png" /> 
</div>

<p align=center>图1:混合系统的结构。HMM对语音信号的序列特性进行建模，DNN对所有聚类后的状态（聚类后的三音素状态）的似然度进行建模[2-1]。这里对时间上的不同点采用同样的DNN</p>

在20世纪90年代中叶，这种混合模型就已经被提出，在大词汇连续语音识别系统中，他被认为是一种非常有前景的技术。在文献`[2,3,4]`中，他被称为DNN-HMM混合模型。在早期基于混合模型的方法中，**通常使用上下文无关的音素状态作为DNN训练的标注信息**，并且只用于小词汇任务。DNN-HMM随后被扩展到上下文相关的音素建模`[6]`,以及用于中型和大词表的自动语音识别任务`[5]`.DNN-HMM的应用中也包含循环神经网路哦的结构。

然而，在早期基于上下文相关的DNN-HMM混合结构`[7]`研究中，对上下文相关音素的后验概率建模为：
$$p(s_i,c_j|x_t)=p(s_i|x_t)p(c_i|s_j,x_t)$$

或者

$$p(s_i,c_j|x_t)=p(c_i|x_t)p(s_i|c_j,x_t)$$

其中，$x_t$是在时刻$t$的声学观察值，$c_j$是聚类后的上下文种类$\{c_1,...,c_J\}$中的一种，$s_i$是一个上下文无关的音素或者音素中的状态。DNN用来估计$p(s_i|x_t)$和$p(c_i|s_j,x_t)$.**尽管这些上下文相关的DNN-HMM模型在一些任务中性能优于GMM-HMM，但其改善并不大。**

这些早期的混合模型有一些重要的局限性。例如，由于计算能力的限制，人们很少使用拥有两层隐层以上的DNN模型，而上述的上下文相关模型不能够利用很多在GMM-HMM框架下很有效的技术。

最近的技术发展`[7-13]`则说明，如下几个改变可以使我们获得重大的识别性能提升：首先，我们把传统的浅层网络替换成深层（可选择的预训练）神经网络。其次，使用聚类后的状态（绑定后的三音素状态）代替单音素的状态作为神经网络的输出单元。这种改善后的DNN-HMM混合模型称为CD-DNN-HMM`[8]`直接为聚类后的状态建模同时也带来其他两个好处：首先，在实现一个CD-DNN-HMM系统的时候，对已存在的CD-DNN-HMM系统修改最小。其次，既然DNN输出单元可以直接反应性能的改善，任何在CD-DNN-HMM系统中模型单元的改善（例如：跨词三音素模型）同样可以适用于CD-DNN-HMM系统。

在CD-DNN-HMM中，对于所有的状态$s\in [1,S]$，我们只训练一个完整的DNN来估计状态的后验概率$p(q_t=s|x_t)$。这和传统的GMM不同，因为GMM框架下，我们会使用其多个不同的GMM对不同的状态建模。除此之外，典型的DNN输入不是单一的一帧，而是一个$2w+1$（如9-13）帧大小的窗口特征$x_t=[o_{max(0,t-w)}...o_t...o_{min(T,t+w)}]$,这使得相邻帧的信息可以被有效的利用。

**2.用CD-DNN-HMM解码**

在解码过程中，既然HMM需要似然度$p(x_t|q_t)$，而不是后验概率，我们就需要把后验概率转为似然度：
$$p(x_t|q_t=s)=p(q_t=s|x_t)p(x_t)/p(s)$$

其中$p(s)=\frac{T_s}{T}$是从训练集中统计的每个状态（聚类后的状态）的先验概率，$T_s$是标记属于状态$s$的帧数，$T$是总帧数。$p(x_t)$是与字词序列无关的，计算时可以忽略，这样就得到经过缩放的似然度：
$$\bar{p}(x_t|q_t)=p(q_t=s|x_t)/p(s)$$

尽管在一些条件下除以先验概率$p(s)$可能不能改善识别率。但是他在缓解标注不平衡问题中是非常重要的，特别是训练语句中包含很长的静音片段时就更是如此。

总之，在CD-DNN-HMM解码出的字词序列$\hat(w)$是由以下公式确定的
$$\hat{w}=arg max_{w}p(w|x)=arg max_{w}p(x|w)p(w)/p(x)=argmax_{w}p(x|w)p(w)$$

其中$p(w)$是*语言模型*，以及：

$$p(x|w)=\sum_{q}p(x,q|w)p(q|w) \approx max\pi(q_0)\prod^{T}_ {t=1}a_{q_{t-1}q_t}\prod^{t}_{t=0}p(q_t|x_t)/p(q_t)$$

是*声学模型*，其中$p(q_t|x_t)$由DNN计算得到，$p(q_t)$是状态的先验概率，$\pi(q_0)$和$a_{q_{t-1}q_t}$分别是初始状态概率和状态转移概率，由HMM决定。和GMM-HMM类似，语言模型权重系数$\lambda$通常被用于平衡声学模型和语言模型得分，最终解码路径由以下公式确定(取log)
$$\hat{w}=argmax_w[logp(x|w)+\lambda logp(w)]$$

**3.CD-DNN-HMM训练过程**

可以使用嵌入的维特比算法来训练CD-DNN-HMM，主要步骤参考算法1。CD-DNN-HMM包含三个组成部分，一个深度神经网络DNN,一个隐马尔可夫模型HMM,以及一个状态先验概率分布prior.由于CD-DNN-HMM的第一步就是使用训练数据训练一个GMM-HMM系统。因为DNN训练的标注是由GMM-HMM系统采用维特比算法产生得到的，而且标注的质量会影响DNN系统的性能。因此，训练一个好的GMM-HMM系统作为初始模型就非常重要。

一旦训练好GMM-HMM模型hmm0，我们就可以创建一个从状态名字到senoneID（每个物理三音素拥有如干个（例如3个）绑定状态（用senones表示））的映射。这个从状态到senoneID的映射(stateTosenoneIDMap)的简历并不简单。这是因为每个逻辑三音素HMM是由经过聚类后的一些列物理三音素HMM代表的。换句话说，如干个逻辑三音素可能映射到相同的物理三音素。

<div align=center>
    <img src="zh-cn/img/ch4/p2.jpg" width=80% /> 
</div>

<p align=center>算法1：训练CD-DNN-HMM的主要步骤</p>

使用已经训练好的GMM-HMM模型hmm0,我们可以在训练数据上采用维特比算法生成一个状态层面上的强制对齐，利用stateTosenoneIDMap，我们能够把其中的状态名转为senoneIDs。然后可以生成从特征到senoneID的映射对(featuresenoneIDPairs)来训练DNN.相同的featuresenoneIDPairs也被用来估计senone先验概率。

利用GMM-HMM模型hmm0,我们也可以生成一个新的隐马尔可夫模型hmm,其中包含和hmm0相同的状态转移概率，以便在DNN-HMM系统中使用。一个简单的方法是把hmm0中的每个GMM(即每个senoneID模型)用一个（假的）一维单高斯模型代替。搞死模型的方差（或者说是精度）是无所谓的，他可以设置成任意的正整数（例如总设置成1）均值被设置为其对应的senoneID。应用这个技巧之后，计算每个senone的后验概率就等价于从DNN的输出向量中查表，找到索引是senoneID的输出对数概率。

在这个过程中，我们假定一个CD-DNN-HMM存在，并被用于生成senone对齐。在这种情况下，用于对三音素状态聚类的决策树也是在GMM-HMM训练的过程中构建的。但这其实不是必须的，如果我们想完全去除图中的GMM-HMM步骤，可以通过均匀的把每个句子分段(称为flat-start)来构建一个但高斯模型，并使用这个信息作为训练标注。这可以形成一个单因素DNN-HMM，我们可以用它重新对句子进行对齐。然后可以对单个音素估计一个单高斯模型，并采用传统方法构建决策树。事实上，这种无需GMM的CD-DNN-HMM是能够成功训练的，这一成果发表在`[14]`.

对含有$T$帧的句子，嵌入的维特比训练算法最小化交叉熵的平均值，其等价于负对数似然
$$J_{NLL}(W,b;x,q)=-\sum^{T}_{t=1}logp(q_t|x_t;W,b)$$

如果新模型$(W^{'},b^{'})$相比于就模型$(W,b)$在训练准则上有改进，我们有
$$-\sum^{T}_ {t=1} log p(q_t|x_t;W^{'},b^{'}) < - \sum ^{T}_ {t=1} log p(q_t|x_t;W,b) $$

对于每个对齐后的句子的分数为

<div align=center>
    <img src="zh-cn/img/ch4/p3.jpg" width=80% /> 
</div>

换句话说，新的模型不仅能提高帧级别交叉熵，而且能够提高给定字词序列的句子似然分数。这里证明了嵌入式的维特比算法的正确性。`[15]`中给出了另一个不同的嵌入式维特比训练算法有效性的证明。值得一提的是，在这个训练过程中，尽管所有的竞争词的分数和总体上是下降的，但并不保证每个竞争词的分数都会下降。而且，上述说法（提高句子似然度）一般说虽然是正确的，但并不保证对每个单独的句子都正确。如果平均的交叉熵改善很小，尤其是当这个很小的改善来自对静音片段更好的建模时，识别的准确度可能会降低。一个原理上更合理的CD-DNN-HMM方法是使用“序列鉴别性训练准则”(这里将不讨论这个方法)


**4.上下文窗口的影像**

使用一个窗（典型的是9到13）包含的全部帧特征作为CD-DNN-HMM的输入可以实现优异的性能。显然，使用一个长的窗口帧，DNN模型可以利用相邻帧信息。引入相邻帧，DNN也可以对不同特征帧之间的相互关系进行建模，这样部分缓和了传统的HMM无法满足观察独立性假设的问题。

每个字词序列的分数通过以下公式得到

$$logp(x|w)=log\pi(q_0)+\sum^{T}_ {t=1} log(a_{q_{t-1}q_t})+\sum^{N}_ {n=1}[logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)]$$

其中，$T$是特征的长度，$N<T$是状态序列的长度，$s_n$是状态序列中第$n$个状态，$q_t$是在$t$时刻的状态，$t_n$是第$n$个状态的起始时间。这里假设状态的时长可以用一个马尔可夫链来模拟。注意，观察值分数$logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)$表示在给定状态$s_n$的情况下，观察到的特征段的对数似然概率，他可被用于基于分段的模型`[15]`,在HMM中，每个特征帧都假设与其他特征帧条件独立，因此

$$logp(o_{t_n},...,o_{t_{n+1}-1}|s_n) \simeq \sum^{t_{n+1}-1}_{t=t_n}[logp(o_t|s_n)]$$

我们知道这个假设在真实世界中是不成立的，对给定相同的状态，既然相邻的帧是互相关的，为了对帧之间的相关性建模，段的分数应该估计为
$$logp(o_{t_n},...,o_{t_{n+1}-1}|s_n)=\sum^{t_{n+1}-1}_{t=t_n}logp(o_t|s_n,o_{t_n},...,o_{t-1})$$

我们知道，如果两帧相隔太远（例如超过M帧）。他们可以被认为是不相关。在这个条件下，以上分数能够近似的表示为：

<div align=center>
    <img src="zh-cn/img/ch4/p4.jpg" width=80% /> 
</div>

其中，$c$是一个与$s_n$不相关的常量，$x^{M}_ t=\{o_{t-M},...,o_{t-1},o_t\}$是M帧拼接而成的特征向量。我们假设状态先验概率和观察值不相关。可以看到DNN模型中引入邻接帧（例如：估计$p(s_n|x^M_{t})$)我们可以更加准确的估计分段函数，同时还可以有效的利用HMM中独立性的假设。



**5.CD-DNN-HMM的消融实验**

在许多大词汇连续语音识别任务中，CD-DNN-HMM比GMM-HMM表现更好，因此，了解哪些模块或者过程对此做了贡献是很重要的。本节将会讨论哪些决策会影响识别准确性。特别的，我们会在实验上比较以下几种决策的表现差别：

+ 单音素对齐和三音素对齐
+ 单音素状态集和三音素状态集
+ 使用浅层和深层神经网络
+ 调整HMM的转移概率或者不调

一系列研究的实验结果`[7,8,12,16,13]`表明，带来性能提升的三个关键因素是：

+ 使用足够深的深度神经网络
+ 使用一长段的帧作为输入
+ 直接对三音素进行建模
  
在所有的试验中，来自CD-DNN-HMM的多层感知器模型(DNN)的后验概率代替GMM,但其他保持不变。


5.1 进行比较和分析的数据集和实验

+ 必应（bing）移动语音搜索数据集

必应移动语音搜索（VS）应用让用户在自己的移动手机上做全美国的商业和网页搜索。用在实验中的这个商业搜索数据集采集于2008年的真实应用场景，当时这个应用被限制在位置和业务查询`[16]`.所有的音频文件的采样率为8kHz，并用GSM编码器编码。这个数据集具有挑战性，因为它包含多种变化：噪声，音乐，旁人说话，口音，错误的发音，犹豫，重复，打断和不同的音频信道。

数据集被划分为训练集，开发集和测试集。数据集根据查询的时间戳进行分割，这是为了模拟真实数据采集和训练过程，并避免三个集合之间的重叠。训练集的所有查询比开发集的查询早，后者比测试集的查询早。我们使用卡内基-梅隆大学的共开词典。在测试集中使用了一个包含了65K个一元词组，320万个二元词组和150万个三元词组的归一化的全国范围的语言模型，是用数据和查询日志训练的，混淆度为117。


<div align=center>
    <img src="zh-cn/img/ch4/p5.png"  /> 
</div>
<p align="center">必应移动搜索数据集 </p>

我们使用句子错误率（SER）,而不是词错误率（WER）来衡量系统在这个任务上的表现。平均句子长度为2.1个词，因此句子一般来说比较短。另外，用户最关心的是他们能否用最少的尝试次数来找到事物或地点。他们一般会重复识别错误的词。另外，在拼写中有巨大的不一致，因此用句子错误率更加方便。在使用者个65K大词表的语言模型中，开发集和测试集在句子层面上的未登录词（Out-of-vocabulary words)比率都为6%，也就是说在这种配置下最好的可能的句子错误率就是6%。

GMM-HMM采用了状态聚类后的跨词三音素模型。训练采用的准则是最大似然（ML),最大互信息（MMI)和最小音素错误（MPE)准则。试验中采用39维的音频特征，其中13维是静态的梅尔倒谱系数（MFCC)(C0被能量替代)，以及其一阶和二阶导数（差分）这些特征采用频谱均值归一化算法进行预处理。

基线系统在开发集上调试了如此下参数，状态聚类的结构，三音素数量，以及高斯分裂的策略。最后所有的系统有35K个逻辑三音素和2K个物理三音素，761个共享的状态（三音素），每个状态是24个高斯GMM模型，GMM-HMM基线的结果在下表。

<div align=center>
    <img src="zh-cn/img/ch4/p6.png"  /> 
</div>
<p align="center">CD-GMM-HMM系统在必应数据集上的SER </p>

对VS数据集上的所有CD-DNN-HMM实验，DNN的输入特征是11帧的MFCC特征。在DNN预训练时，所有的层对每个采样都采用了$1.5e^{-4}$的学习率。在训练中，在前六次迭代中，学习率为$3e^{-3}$每帧，在最后6次迭代中是$8e^{-5}$。在所有的试验中，minibatch的大小为256，惯性系数为0.9.这些参数都是手动设定的，他们基于单隐层神经网络的前期实验，如果尝试更多超参数的设置，可能得到的效果会更好。

+ Switchboard数据集

Switchboard(SWB)数据集`[19,20]`是一个交谈式电话语音数据集。他有三个配置，训练集分别为30个小时（SWB-I训练集的一个随机子集)，309个小时（SWB-I全部训练集）和2000个小时（加上Fisher训练集）。在所有的配置下，NIST2000Hub5测试集1831段的SWB部分和NIST2003春季丰富语音标注集（RT03S,6.3小时）的FSH部分被用作了测试集。系统使用了13维的PLP特征（包括三阶差分），做了滑动窗口的均值-方差归一化，然后使用异方差线性判别式（HLDA）`[21]`降维到39维。在30小时，309小时，2000小时三个配置下，说话人无关的跨词三音素模型使用了1504（40高斯），9304（40高斯）和18804(72高斯)的共享状态（GMM-HMM系统）。三元词组语言模型使用2000个小时的Fisher标注数据训练，然后与一个基于书面语文本数据的三元组语言模型进行插值。当使用85K词典时，测试集的混淆度为84.

DNN系统使用SGD训练，除了第一次跌单batch为356帧，其余batch设为1204帧。在深度置信网络预训练的时候batch为256.

对于预训练，每个样本的学习率为$1.5e^{-4}$.对于前24个小时的训练数据，每帧的学习率为$3e^{-3}$，三次迭代后改为$8e^{-5}$,惯性系数为0.9。这些参数设置跟语音搜索数据集(VS)相同。

5.2 对单音素或者三音素的状态进行建模



5.3 越深越好


5.4 利用相邻的语音帧


5.5 预训练


5.6 训练数据的标注质量影像



5.7 调整转移概率




**6.基于KL距离的HMM**